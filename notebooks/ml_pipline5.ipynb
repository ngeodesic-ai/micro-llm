{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "915a4539-cf38-4919-84d0-cda9c362e18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import json, csv, sys, os, time\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- sklearn bits\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# --- sentence-transformers for embeddings\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "except Exception as e:\n",
    "    SentenceTransformer = None\n",
    "    print(\"[WARN] sentence-transformers not importable right now. Install it to train/encode.\", file=sys.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e44704-2085-4331-9ef9-b0844e255f90",
   "metadata": {},
   "source": [
    "## Mapper (Part 1): Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0973c2e9-6069-4c6e-91e7-7841cb39522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- SBERT encoder (pipeline compatible) ----------------\n",
    "class SBERTEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Lightweight sentence-embedding transformer for sklearn pipelines.\"\"\"\n",
    "    def __init__(self, model_name=\"sentence-transformers/all-MiniLM-L6-v2\", batch_size: int = 64, normalize: bool = True):\n",
    "        self.model_name = model_name\n",
    "        self.batch_size = batch_size\n",
    "        self.normalize = normalize\n",
    "        self._model = None\n",
    "\n",
    "    def _ensure_model(self):\n",
    "        if self._model is None:\n",
    "            if SentenceTransformer is None:\n",
    "                raise RuntimeError(\"sentence-transformers is required to encode prompts.\")\n",
    "            self._model = SentenceTransformer(self.model_name)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self._ensure_model()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        self._ensure_model()\n",
    "        embs = self._model.encode(\n",
    "            list(X),\n",
    "            batch_size=self.batch_size,\n",
    "            show_progress_bar=False,\n",
    "            normalize_embeddings=self.normalize,\n",
    "        )\n",
    "        return np.asarray(embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66c70911-57fd-40e1-9cd1-282e014e4fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ I/O helpers ------------------------\n",
    "def _read_prompts_jsonl(path: str) -> List[str]:\n",
    "    prompts: List[str] = []\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                rec = json.loads(line)\n",
    "                p = rec.get(\"prompt\", \"\").strip()\n",
    "                if p:\n",
    "                    prompts.append(p)\n",
    "            except Exception:\n",
    "                # tolerate occasional garbage lines\n",
    "                continue\n",
    "    return prompts\n",
    "\n",
    "def _read_labels_csv(path: str) -> Dict[str, str]:\n",
    "    gold: Dict[str, str] = {}\n",
    "    df = pd.read_csv(path)\n",
    "    if not {\"prompt\", \"label\"}.issubset(df.columns):\n",
    "        raise ValueError(f\"labels_csv must have columns ['prompt','label'], got {df.columns.tolist()}\" )\n",
    "    for _, row in df.iterrows():\n",
    "        p = str(row[\"prompt\"]).strip()\n",
    "        y = str(row[\"label\"]).strip()\n",
    "        if p:\n",
    "            gold[p] = y\n",
    "    return gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09c61fca-6301-43c7-9fb7-7143b93abcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ Training ------------------------\n",
    "def train_mapper(\n",
    "    labels_csv: str,\n",
    "    out_path: str = \".artifacts/defi_mapper.joblib\",\n",
    "    sbert_model: str = \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    C: float = 8.0,\n",
    "    max_iter: int = 2000,\n",
    "    calibrate: bool = True,\n",
    "    calibration_method: str = \"auto\",  # 'auto' | 'isotonic' | 'sigmoid'\n",
    "    calibration_cv: int = 3,\n",
    ") -> str:\n",
    "    \"\"\"Train a SBERT + LogisticRegression pipeline, optionally calibrated, and dump to joblib.\"\"\"\n",
    "    os.makedirs(os.path.dirname(out_path) or \".\", exist_ok=True)\n",
    "\n",
    "    df = pd.read_csv(labels_csv)\n",
    "    need = {\"prompt\",\"label\"}\n",
    "    if not need.issubset(df.columns):\n",
    "        raise SystemExit(f\"[train_mapper] labels_csv must have columns {need}, got {df.columns.tolist()}\" )\n",
    "    df = df.dropna(subset=[\"prompt\",\"label\"]).copy()\n",
    "    df[\"prompt\"] = df[\"prompt\"].astype(str).str.strip()\n",
    "    df[\"label\"]  = df[\"label\"].astype(str).str.strip()\n",
    "    df = df[df[\"prompt\"].str.len() > 0]\n",
    "    if df.empty:\n",
    "        raise SystemExit(\"[train_mapper] No non-empty prompts after cleaning.\")\n",
    "\n",
    "    X = df[\"prompt\"].tolist()\n",
    "    y = df[\"label\"].tolist()\n",
    "\n",
    "    base = LogisticRegression(max_iter=max_iter, C=C, class_weight=\"balanced\", random_state=0)\n",
    "\n",
    "    model = base\n",
    "    if calibrate:\n",
    "        # pick a safe calibration automatically for tiny classes\n",
    "        from collections import Counter\n",
    "        cnt = Counter(y); m = min(cnt.values())\n",
    "        method = calibration_method; cv = calibration_cv\n",
    "        if method == \"auto\":\n",
    "            if m >= max(3, cv):\n",
    "                method, cv = \"isotonic\", max(3, cv)\n",
    "            elif m >= 2:\n",
    "                method, cv = \"sigmoid\", max(2, min(m, cv))\n",
    "            else:\n",
    "                print(\"[train_mapper] Not enough per-class samples for calibration; skipping.\", file=sys.stderr)\n",
    "                method = None\n",
    "        if method in (\"isotonic\",\"sigmoid\"):\n",
    "            try:\n",
    "                model = CalibratedClassifierCV(estimator=base, method=method, cv=cv)  # sklearn>=1.3\n",
    "            except TypeError:\n",
    "                model = CalibratedClassifierCV(base_estimator=base, method=method, cv=cv)  # older sklearn\n",
    "\n",
    "    pipe = make_pipeline(SBERTEncoder(sbert_model), model)\n",
    "    pipe.fit(X, y)\n",
    "    joblib.dump(pipe, out_path)\n",
    "    print(f\"[train_mapper] wrote: {out_path}  (n={len(X)})\")\n",
    "    return out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4059881-0d71-45ac-b59e-a9d89112786f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ Prediction & Metrics ------------------------\n",
    "@dataclass\n",
    "class PredictResult:\n",
    "    rows_csv: Optional[str]\n",
    "    metrics: Optional[dict]\n",
    "\n",
    "\n",
    "def _predict_proba(mapper, prompts: List[str]) -> Tuple[List[str], np.ndarray]:\n",
    "    if hasattr(mapper, \"classes_\"):\n",
    "        classes = list(map(str, mapper.classes_))\n",
    "    else:\n",
    "        # try to infer from predict_proba later\n",
    "        classes = None\n",
    "\n",
    "    if hasattr(mapper, \"predict_proba\"):\n",
    "        probs = mapper.predict_proba(prompts)\n",
    "        probs = np.asarray(probs, dtype=float)\n",
    "        if classes is None:\n",
    "            classes = list(map(str, getattr(mapper, \"classes_\", [])))\n",
    "        return classes, probs\n",
    "\n",
    "    # decision_function -> softmax fallback\n",
    "    if hasattr(mapper, \"decision_function\"):\n",
    "        logits = mapper.decision_function(prompts)\n",
    "        logits = np.asarray(logits, dtype=float)\n",
    "        if logits.ndim == 1:\n",
    "            logits = logits.reshape(-1, 1)\n",
    "        ex = np.exp(logits - logits.max(axis=1, keepdims=True))\n",
    "        probs = ex / (ex.sum(axis=1, keepdims=True) + 1e-12)\n",
    "        if classes is None:\n",
    "            classes = list(map(str, getattr(mapper, \"classes_\", [])))\n",
    "        return classes, probs\n",
    "\n",
    "    # predict-only fallback (degenerate probs)\n",
    "    preds = np.array(mapper.predict(prompts), dtype=object).reshape(-1, 1)\n",
    "    classes = list(sorted(set(map(str, preds.flatten().tolist()))))\n",
    "    idx = {c:i for i,c in enumerate(classes)}\n",
    "    probs = np.zeros((len(prompts), len(classes)), dtype=float)\n",
    "    for r, y in enumerate(preds.flatten().tolist()):\n",
    "        probs[r, idx[str(y)]] = 1.0\n",
    "    return classes, probs\n",
    "\n",
    "\n",
    "def predict_prompts(\n",
    "    mapper_path: str,\n",
    "    prompts_jsonl: str,\n",
    "    labels_csv_pred: Optional[str] = None,\n",
    "    threshold: float = 0.6,\n",
    "    out_rows_csv: Optional[str] = None,\n",
    ") -> PredictResult:\n",
    "    \"\"\"Load mapper, score prompts, write per-row CSV, and (optionally) compute quick metrics.\"\"\"\n",
    "    mapper = joblib.load(mapper_path)\n",
    "    prompts = _read_prompts_jsonl(prompts_jsonl)\n",
    "    classes, probs = _predict_proba(mapper, prompts)\n",
    "\n",
    "    top_idx = probs.argmax(axis=1)\n",
    "    top_conf = probs.max(axis=1)\n",
    "    fired = (top_conf >= threshold)\n",
    "    preds = np.array([classes[i] for i in top_idx], dtype=object)\n",
    "    pred_labels = np.where(fired, preds, \"\")\n",
    "\n",
    "    rows = []\n",
    "    if labels_csv_pred:\n",
    "        gold = _read_labels_csv(labels_csv_pred)\n",
    "    else:\n",
    "        gold = {}\n",
    "\n",
    "    for p, yhat, conf, fire in zip(prompts, pred_labels, top_conf, fired):\n",
    "        rows.append({\n",
    "            \"prompt\": p,\n",
    "            \"predicted\": yhat,\n",
    "            \"confidence\": float(conf),\n",
    "            \"abstain\": (not bool(fire)),\n",
    "            \"threshold\": float(threshold),\n",
    "            \"gold_label\": gold.get(p, \"\")\n",
    "        })\n",
    "\n",
    "    rows_csv_path = None\n",
    "    if out_rows_csv:\n",
    "        os.makedirs(os.path.dirname(out_rows_csv) or \".\", exist_ok=True)\n",
    "        import csv as _csv\n",
    "        with open(out_rows_csv, \"w\", newline=\"\") as f:\n",
    "            w = _csv.DictWriter(f, fieldnames=[\"prompt\",\"gold_label\",\"predicted\",\"confidence\",\"abstain\",\"threshold\"]\n",
    "            )\n",
    "            w.writeheader()\n",
    "            for r in rows:\n",
    "                w.writerow({k: r[k] for k in w.fieldnames})\n",
    "        rows_csv_path = out_rows_csv\n",
    "        print(f\"[predict] wrote rows: {rows_csv_path}  (n={len(rows)})\")\n",
    "\n",
    "    # quick metrics (if gold labels provided)\n",
    "    metrics = None\n",
    "    if gold:\n",
    "        total = len(prompts)\n",
    "        abstain_ct = sum(1 for r in rows if r[\"abstain\"])\n",
    "        fired_ct   = total - abstain_ct\n",
    "        correct_on_fired = sum(1 for r in rows if (not r[\"abstain\"]) and r[\"predicted\"] == r[\"gold_label\"])\n",
    "        overall_correct  = sum(1 for r in rows if r[\"predicted\"] == r[\"gold_label\"])  # empty pred never equals gold\n",
    "\n",
    "        accuracy_on_fired = (correct_on_fired / fired_ct) if fired_ct else None\n",
    "        overall_accuracy  = overall_correct / total if total else None\n",
    "\n",
    "        metrics = {\n",
    "            \"threshold\": float(threshold),\n",
    "            \"total\": total,\n",
    "            \"abstain\": abstain_ct,\n",
    "            \"abstain_rate\": abstain_ct / total if total else None,\n",
    "            \"coverage\": fired_ct / total if total else None,\n",
    "            \"fired\": fired_ct,\n",
    "            \"correct_on_fired\": correct_on_fired,\n",
    "            \"accuracy_on_fired\": accuracy_on_fired,\n",
    "            \"overall_correct\": overall_correct,\n",
    "            \"overall_accuracy\": overall_accuracy,\n",
    "        }\n",
    "        print(\"[metrics]\", metrics)\n",
    "\n",
    "    return PredictResult(rows_csv=rows_csv_path, metrics=metrics)\n",
    "\n",
    "# ------------------------ CLI (optional) ------------------------\n",
    "def _as_bool(x: str) -> bool:\n",
    "    return str(x).strip().lower() in {\"1\",\"true\",\"t\",\"yes\",\"y\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8bbd4f0-91df-42f9-b74c-48b4adb5d9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, csv, json, os, sys, time\n",
    "def get_args():\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"--backend\",       default=\"wordmap\", help=\"wordmap|sbert\")\n",
    "    ap.add_argument(\"--model_path\",    default=\".artifacts/defi_mapper.joblib\")\n",
    "    ap.add_argument(\"--prompts_jsonl\", default=\"tests/fixtures/defi/defi_mapper_5k_prompts.json\")\n",
    "    ap.add_argument(\"--labels_csv_pred\", default=\"tests/fixtures/defi/defi_mapper_labeled_5k.csv\")\n",
    "    ap.add_argument(\"--train_labels_csv\", default=\"tests/fixtures/defi/defi_mapper_labeled_large.csv\")\n",
    "    ap.add_argument(\"--thresholds\",    default=\"0.5,0.55,0.6,0.65,0.7\")\n",
    "    ap.add_argument(\"--max_iter\",    default=\"2000\")\n",
    "    ap.add_argument(\"--C\",    default=\"8\")\n",
    "    ap.add_argument(\"--calibrate\",    default=\"True\")\n",
    "    ap.add_argument(\"--calibration_method\", choices=[\"auto\",\"isotonic\",\"sigmoid\"], default=\"auto\")\n",
    "    ap.add_argument(\"--calibration_cv\", type=int, default=3)\n",
    "    ap.add_argument(\"--sbert_model\", default=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    ap.add_argument(\"--threshold\", type=float, default=0.6)\n",
    "    ap.add_argument(\"--out_path\", default=\"defi_mapper_embed.joblib\")\n",
    "    ap.add_argument(\"--out_dir\",       default=\"\")\n",
    "    ap.add_argument(\"--out_rows_csv\", default=\".artifacts/m8_rows_simple.csv\")\n",
    "    ap.add_argument(\"--min_overall_acc\", default=None)\n",
    "    \n",
    "    notebook_args = [\n",
    "        \"--backend\", \"sbert\",\n",
    "        \"--model_path\", \".artifacts/defi_mapper.joblib\",\n",
    "        \"--prompts_jsonl\", \"tests/fixtures/defi/defi_mapper_5k_prompts.jsonl\",\n",
    "        \"--labels_csv_pred\",    \"tests/fixtures/defi/defi_mapper_labeled_5k.csv\",\n",
    "        \"--train_labels_csv\", \"tests/fixtures/defi/defi_mapper_labeled_large.csv\",\n",
    "        \"--thresholds\", \"0.5,0.55,0.6,0.65,.7\",\n",
    "        \"--max_iter\", \"2000\",\n",
    "        \"--C\", \"8\",\n",
    "        \"--calibrate\", \"True\",\n",
    "        \"--calibration_method\", \"auto\",\n",
    "        \"--calibration_cv\", \"3\",\n",
    "        \"--threshold\", \"0.5\",\n",
    "        \"--min_overall_acc\", \"0.75\",\n",
    "        \"--sbert_model\", \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        \"--out_path\", \"defi_mapper_embed.joblib\",\n",
    "        \"--out_rows_csv\", \".artifacts/m8_rows_simple.csv\",\n",
    "        \"--out_dir\", \".artifacts/defi/mapper_bench\",\n",
    "    ]\n",
    "    \n",
    "    return ap.parse_args(notebook_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7b1f07-7908-4299-a1a1-d91520357e16",
   "metadata": {},
   "source": [
    "## Mapper (Part 2): Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b0ffa14-fa70-4801-8b79-ae3c50eb2117",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1784: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train_mapper] wrote: defi_mapper_embed.joblib  (n=1000)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cwd =  os.getcwd().replace(\"/notebooks\",\"\")\n",
    "os.chdir(cwd)\n",
    "\n",
    "args = get_args()\n",
    "\n",
    "model_path = train_mapper(\n",
    "        labels_csv=args.train_labels_csv,\n",
    "        out_path=args.out_path,\n",
    "        sbert_model=args.sbert_model,\n",
    "        C=float(args.C),\n",
    "        max_iter=int(args.max_iter),\n",
    "        calibrate=_as_bool(args.calibrate),\n",
    "        calibration_method=args.calibration_method,\n",
    "        calibration_cv=args.calibration_cv\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07f48e35-46f1-4684-8ea4-4bb478abfec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1784: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[predict] wrote rows: .artifacts/m8_rows_simple.csv  (n=5000)\n",
      "[metrics] {'threshold': 0.5, 'total': 5000, 'abstain': 37, 'abstain_rate': 0.0074, 'coverage': 0.9926, 'fired': 4963, 'correct_on_fired': 4941, 'accuracy_on_fired': 0.995567197259722, 'overall_correct': 4941, 'overall_accuracy': 0.9882}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PredictResult(rows_csv='.artifacts/m8_rows_simple.csv', metrics={'threshold': 0.5, 'total': 5000, 'abstain': 37, 'abstain_rate': 0.0074, 'coverage': 0.9926, 'fired': 4963, 'correct_on_fired': 4941, 'accuracy_on_fired': 0.995567197259722, 'overall_correct': 4941, 'overall_accuracy': 0.9882})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = get_args()\n",
    "\n",
    "predict_prompts(\n",
    "        mapper_path=model_path,\n",
    "        prompts_jsonl=args.prompts_jsonl,\n",
    "        labels_csv_pred=(args.labels_csv_pred or None),\n",
    "        threshold=float(args.threshold),\n",
    "        out_rows_csv=args.out_rows_csv\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7883cdd-c248-4295-b011-7c05b3df2f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1784: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['claim_rewards', 'withdraw_asset', 'stake_asset', 'deposit_asset',\n",
       "       'deposit_asset'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mapper\n",
    "mapper = joblib.load(model_path)\n",
    "test_prompts = _read_prompts_jsonl(args.prompts_jsonl)\n",
    "labeled_test_prompts = _read_labels_csv(args.labels_csv_pred)\n",
    "threshold = float(args.threshold)\n",
    "\n",
    "classes, probs = _predict_proba(mapper, test_prompts[0:5])\n",
    "\n",
    "top_idx = probs.argmax(axis=1)\n",
    "top_conf = probs.max(axis=1)\n",
    "fired = (top_conf >= threshold)\n",
    "preds = np.array([classes[i] for i in top_idx], dtype=object)\n",
    "pred_labels = np.where(fired, preds, \"\")\n",
    "pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e983e8b-3863-4923-8fb8-c43c36318d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1784: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['claim_rewards', 'withdraw_asset', 'stake_asset', 'deposit_asset',\n",
       "       'deposit_asset'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prompts = ['sing me a lullaby',\n",
    "                      'what’s the weather in NYC?',\n",
    "                      'open settings',\n",
    "                      'convert centimeters to inches',\n",
    "                      'swap seats with me',\n",
    "                      'hey wats going on']\n",
    "\n",
    "# mapper\n",
    "mapper = joblib.load(model_path)\n",
    "test_prompts = _read_prompts_jsonl(args.prompts_jsonl)\n",
    "labeled_test_prompts = _read_labels_csv(args.labels_csv_pred)\n",
    "threshold = float(args.threshold)\n",
    "\n",
    "classes, probs = _predict_proba(mapper, test_prompts[0:5])\n",
    "\n",
    "top_idx = probs.argmax(axis=1)\n",
    "top_conf = probs.max(axis=1)\n",
    "fired = (top_conf >= threshold)\n",
    "preds = np.array([classes[i] for i in top_idx], dtype=object)\n",
    "pred_labels = np.where(fired, preds, \"\")\n",
    "pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f646b20d-a95f-40b4-a92b-42d8f83a59d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1784: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['claim_rewards', 'withdraw_asset', 'stake_asset', 'deposit_asset',\n",
       "       'deposit_asset'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mapper\n",
    "mapper = joblib.load(model_path)\n",
    "test_prompts = _read_prompts_jsonl(args.prompts_jsonl)\n",
    "labeled_test_prompts = _read_labels_csv(args.labels_csv_pred)\n",
    "threshold = float(args.threshold)\n",
    "\n",
    "classes, probs = _predict_proba(mapper, test_prompts[0:5])\n",
    "\n",
    "top_idx = probs.argmax(axis=1)\n",
    "top_conf = probs.max(axis=1)\n",
    "fired = (top_conf >= threshold)\n",
    "preds = np.array([classes[i] for i in top_idx], dtype=object)\n",
    "pred_labels = np.where(fired, preds, \"\")\n",
    "pred_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63f8c4c-73d4-4d0f-8fad-f1370000e688",
   "metadata": {},
   "source": [
    "## Auditor (Part 2): Setup SbertEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "455ae616-5ce9-491f-b464-eb222b8f1614",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRIMITIVE = \"swap_asset\"\n",
    "\n",
    "# get training prompts\n",
    "N_TRAIN = 1000\n",
    "train_prompts = _read_labels_csv(args.train_labels_csv)\n",
    "train_deposit_labels = []\n",
    "labeled_train_deposit_prompts = {}\n",
    "\n",
    "for k, g in enumerate(train_prompts):\n",
    "\n",
    "    if(train_prompts[g] == PRIMITIVE):\n",
    "        labeled_train_deposit_prompts[k] = g\n",
    "        train_deposit_labels.append(1)\n",
    "    else:\n",
    "        train_deposit_labels.append(0)\n",
    "        \n",
    "    if (k == N_TRAIN):\n",
    "        break;\n",
    "\n",
    "train_deposit_prompts = list(labeled_train_deposit_prompts.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ed10971-63d3-40da-a755-d5f3eaccb849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: 'convert 7064 USDT into LINK via sushiswap on arbitrum — minimize gas, safe mode',\n",
       " 20: 'convert 704.7582 AAVE into USDT via uniswap on arbitrum — minimize gas',\n",
       " 23: 'swap 860.4607 ARB to WBTC on sushiswap arbitrum with slippage 0.1% — asap',\n",
       " 31: 'swap 0.240081 WBTC to WETH on balancer solana',\n",
       " 33: 'market swap 5930 USDT->SOL using sushiswap on arbitrum — safe mode',\n",
       " 42: 'market swap 26.3876 MATIC->WBTC using sushiswap on polygon with slippage 0.1% — right away',\n",
       " 46: 'trade 6823 USDC for ETH on curve (arbitrum) — now',\n",
       " 60: 'trade 3389.1714 OP for WBTC on curve (base) with slippage 1% — asap',\n",
       " 61: 'swap 3229.3468 LINK to AAVE on curve avalanche with slippage 0.1%',\n",
       " 63: 'trade 32.883 MATIC for WBTC on curve (avalanche)',\n",
       " 64: 'convert 1216 USDT into WETH via balancer on ethereum',\n",
       " 70: 'swap 684.2186 LINK to USDC on uniswap arbitrum with slippage 0.2% — minimize gas',\n",
       " 78: 'market swap 25.7623 ETH->SOL using balancer on avalanche with slippage 1%',\n",
       " 79: 'swap 22.1568 SOL to ARB on curve ethereum — asap',\n",
       " 90: 'convert 11.5522 ETH into MATIC via sushiswap on base with slippage 0.2%',\n",
       " 112: 'market swap 6682 DAI->ARB using sushiswap on base with slippage 1%',\n",
       " 113: 'market swap 1.327043 BTC->ETH using uniswap on solana with slippage 0.2% — high yield mode',\n",
       " 114: 'swap 17722 USDT to MATIC on sushiswap avalanche with slippage 0.5% — safe mode',\n",
       " 128: 'swap 21.4244 AVAX to OP on uniswap optimism',\n",
       " 131: 'trade 42.474 ETH for USDT on curve (solana) with slippage 0.2%',\n",
       " 132: 'convert 34.6057 ETH into BTC via balancer on polygon with slippage 1%',\n",
       " 133: 'trade 18672 USDT for AAVE on sushiswap (arbitrum)',\n",
       " 140: 'swap 1.258954 BTC to WETH on sushiswap arbitrum — safe mode',\n",
       " 159: 'trade 34.9473 MATIC for BTC on uniswap (polygon) with slippage 0.1%',\n",
       " 168: 'market swap 16193 DAI->LINK using uniswap on solana with slippage 1% — minimize gas, high yield mode'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get test prompts\n",
    "N_TEST = 25\n",
    "labeled_test_prompts = _read_labels_csv(args.labels_csv_pred)\n",
    "labeled_test_deposit_prompts = {}\n",
    "for k, g in enumerate(labeled_test_prompts):\n",
    "\n",
    "    if(labeled_test_prompts[g] == PRIMITIVE):\n",
    "        labeled_test_deposit_prompts[k] = g\n",
    "    if (len(labeled_test_deposit_prompts) == N_TEST):\n",
    "        break;\n",
    "\n",
    "test_deposit_seeds = list(labeled_test_prompts.keys())\n",
    "test_seeds = list(labeled_test_deposit_prompts.values())\n",
    "labeled_test_deposit_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ec695c9-6bdb-4fc3-8106-3c5b0e31805e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    _SBERT_OK = True\n",
    "except Exception:\n",
    "    _SBERT_OK = False\n",
    "\n",
    "class SbertEmbedding:\n",
    "    def __init__(self, model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "        if not _SBERT_OK:\n",
    "            raise RuntimeError(\"sentence-transformers not available; pip install sentence-transformers\")\n",
    "        self.m = SentenceTransformer(model_name)\n",
    "    def encode_one(self, text: str) -> np.ndarray:\n",
    "        v = self.m.encode([text], normalize_embeddings=True)[0]\n",
    "        return v.astype(np.float32)\n",
    "\n",
    "def load_phrases():\n",
    "    default = {\n",
    "        \"deposit_asset\": [\"deposit\",\"top up\",\"add\",\"add funds\",\"fund\",\"supply\",\"put in\", \"move\",\"provide\"],\n",
    "        \"withdraw_asset\": [\"withdraw\",\"cash out\",\"take out\",\"remove\",\"pull\"],\n",
    "        \"swap_asset\": [\"swap\",\"convert\",\"exchange\",\"trade\"],\n",
    "        \"borrow_asset\": [\"borrow\",\"take loan\",\"obtain credit\",\"draw\"],\n",
    "        \"repay_asset\": [\"repay\",\"pay back\",\"settle debt\",\"return loan\"],\n",
    "        \"stake_asset\": [\"stake\",\"lock\",\"bond\",\"delegate\"],\n",
    "        \"unstake_asset\": [\"unstake\",\"unlock\",\"withdraw stake\",\"redeem stake\"],\n",
    "        \"claim_rewards\": [\"claim\",\"collect\",\"harvest\",\"receive rewards\"]\n",
    "    }\n",
    "    return default\n",
    "\n",
    "def build_prototypes(emb, phrases_or_thresholds: dict):\n",
    "    \"\"\"\n",
    "    Accepts either:\n",
    "      A) phrases: {prim: [(phrase, score), (phrase, score), ...]}  or  {prim: [phrase, phrase, ...]}\n",
    "      B) thresholds: {prim: float}  (per-class threshold file)\n",
    "    For (B), we fall back to embedding the primitive name itself.\n",
    "    \"\"\"\n",
    "    proto = {}\n",
    "    for p, val in phrases_or_thresholds.items():\n",
    "        vecs = []\n",
    "        if isinstance(val, (int, float)):\n",
    "            # thresholds file -> fallback: use primitive token as prototype\n",
    "            vecs = [emb.encode_one(p)]\n",
    "        else:\n",
    "            # phrases file: list of phrases or (phrase,score)\n",
    "            if isinstance(val, list) and len(val) > 0:\n",
    "                for item in val:\n",
    "                    if isinstance(item, (list, tuple)) and len(item) > 0:\n",
    "                        phrase = item[0]\n",
    "                    else:\n",
    "                        phrase = item\n",
    "                    vecs.append(emb.encode_one(str(phrase)))\n",
    "            else:\n",
    "                # empty -> fallback\n",
    "                vecs = [emb.encode_one(p)]\n",
    "        proto[p] = np.stack(vecs, axis=0).mean(axis=0)\n",
    "    return proto\n",
    "    \n",
    "def cosine(a, b):\n",
    "    an = a / (np.linalg.norm(a) + 1e-8)\n",
    "    bn = b / (np.linalg.norm(b) + 1e-8)\n",
    "    return float(np.dot(an, bn))\n",
    "\n",
    "def spans_from_prompt(prompt, prototypes, emb, tau_span=0.55):\n",
    "    toks = prompt.strip().split()\n",
    "    spans = []\n",
    "    for n in range(1, min(6, len(toks))+1):\n",
    "        for i in range(0, len(toks)-n+1):\n",
    "            s = \" \".join(toks[i:i+n])\n",
    "            e = emb.encode_one(s)\n",
    "            for k, v in prototypes.items():\n",
    "                sc = max(0.0, cosine(e, v))\n",
    "                if sc >= tau_span:\n",
    "                    t_center = (i + n/2.0) / max(1.0, len(toks))  # normalized [0,1]\n",
    "                    spans.append({\"primitive\": k, \"term\": s, \"score\": round(sc,4), \"t_center\": round(t_center,4)})\n",
    "    # keep top 3 spans per primitive\n",
    "    by_prim = {}\n",
    "    for sp in spans:\n",
    "        by_prim.setdefault(sp[\"primitive\"], []).append(sp)\n",
    "    for k in by_prim:\n",
    "        by_prim[k] = sorted(by_prim[k], key=lambda x: x[\"score\"], reverse=True)[:3]\n",
    "    return by_prim\n",
    "\n",
    "span_map = spans_from_prompt(test_prompt, prototypes, emb, tau_span=0.55)\n",
    "span_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "919a9f40-e6aa-42f1-be78-887eafd64854",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1784: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "emb = SbertEmbedding()\n",
    "phrases = load_phrases()\n",
    "prototypes = build_prototypes(emb, phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2cb4e8e-a547-4230-a852-70382b34be0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'deposit_asset': 0.0837,\n",
       " 'withdraw_asset': 0.0531,\n",
       " 'swap_asset': 0.1479,\n",
       " 'borrow_asset': 0.0,\n",
       " 'repay_asset': 0.0251,\n",
       " 'stake_asset': 0.0,\n",
       " 'unstake_asset': 0.0898,\n",
       " 'claim_rewards': 0.0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prompt = test_seeds[14]\n",
    "tau_span = 0.55\n",
    "\n",
    "# 1) primitive mapping (whole-sentence sim)\n",
    "e = emb.encode_one(test_prompt)\n",
    "primitive_mapping = {k: round(max(0.0, cosine(e, v)), 4) for k, v in prototypes.items()}\n",
    "primitive_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cce1e169-d958-45e0-a98a-731631a57468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'swap_asset': [{'primitive': 'swap_asset',\n",
       "   'term': 'convert',\n",
       "   'score': 0.6612,\n",
       "   't_center': 0.0417}],\n",
       " 'deposit_asset': [{'primitive': 'deposit_asset',\n",
       "   'term': 'into',\n",
       "   'score': 0.5735,\n",
       "   't_center': 0.2917}]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) primitive -> term mapping (span detection)\n",
    "span_map = spans_from_prompt(test_prompt, prototypes, emb, tau_span=0.55)\n",
    "span_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd39976c-c730-4333-945a-c7f402aa7eb4",
   "metadata": {},
   "source": [
    "## Auditor (Part 2): Audit from SBERT span map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cf3d1f7-cbaa-491d-8b4e-748ffa11a862",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_test_seeds = ['sing me a lullaby',\n",
    "                      'what’s the weather in NYC?',\n",
    "                      'open settings',\n",
    "                      'convert centimeters to inches',\n",
    "                      'swap seats with me',\n",
    "                      'hey wats going on']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa1e5761-fdab-466a-8e61-aefa1d3a5442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ABSTAIN / prompt: sing me a lullaby\n",
      "1 ABSTAIN / prompt: what’s the weather in NYC?\n",
      "2 ABSTAIN / prompt: open settings\n",
      "3 PASS / prompt: convert centimeters to inches / primitives: ['swap_asset']\n",
      "4 PASS / prompt: swap seats with me / primitives: ['swap_asset']\n",
      "5 ABSTAIN / prompt: hey wats going on\n"
     ]
    }
   ],
   "source": [
    "import json, math, hashlib\n",
    "import numpy as np\n",
    "\n",
    "# ---------- utilities ----------\n",
    "def kaiser_window(L=160, beta=8.6):\n",
    "    # smooth, MF-friendly lobe (unit norm)\n",
    "    n = np.arange(L)\n",
    "    w = np.i0(beta * np.sqrt(1 - ((2*n)/(L-1) - 1)**2))\n",
    "    w = w / (np.linalg.norm(w) + 1e-9)\n",
    "    return w.astype(\"float32\")\n",
    "\n",
    "def matched_filter_scores(traces, q):\n",
    "    scores, nulls, peaks = {}, {}, {}\n",
    "    L = len(q)\n",
    "    for k, x in traces.items():\n",
    "        if len(x) < L:  # pad if needed\n",
    "            x = np.pad(x, (0, L - len(x)))\n",
    "        # convolution as correlation (flip q)\n",
    "        r = np.convolve(x, q[::-1], mode=\"valid\")\n",
    "        peak = float(r.max()) if r.size else 0.0\n",
    "        scores[k] = peak\n",
    "        nulls[k]  = float(np.sqrt(np.sum(x**2)) * (np.linalg.norm(q))) / max(len(x),1)  # crude noise floor\n",
    "        peaks[k]  = {\"score\": peak, \"t_idx\": int(np.argmax(r)) if r.size else 0}\n",
    "    return scores, nulls, peaks\n",
    "\n",
    "def decide(scores, nulls, tau_rel=0.60, tau_abs=0.93):\n",
    "    accepted, seq = {}, []\n",
    "    for k in scores:\n",
    "        s, n = scores[k], nulls[k] + 1e-9\n",
    "        rel = s / n\n",
    "        if (rel >= tau_rel) and (s >= tau_abs):\n",
    "            accepted[k] = {\"score\": round(s, 4), \"rel\": round(rel, 3), \"null\": round(n, 4)}\n",
    "            seq.append((k, s))\n",
    "    seq.sort(key=lambda z: -z[1])\n",
    "    return [k for k, _ in seq], accepted\n",
    "\n",
    "# ---------- core: audit from spans ----------\n",
    "def audit_from_span_map(prompt:str,\n",
    "                        primitive_to_term_mapping:dict,\n",
    "                        T:int=720,\n",
    "                        tau_span:float=0.55,\n",
    "                        tau_abs:float=0.93,\n",
    "                        tau_rel:float=0.60,\n",
    "                        sigma:float=0.02,\n",
    "                        fuse_per_primitive:bool=False):\n",
    "    \"\"\"\n",
    "    primitive_to_term_mapping: {\n",
    "      \"deposit_asset\": [{\"term\":\"add\",\"score\":0.6391,\"t_center\":0.0833}, ...],\n",
    "      ...\n",
    "    }\n",
    "    \"\"\"\n",
    "    # 1) init noise traces\n",
    "    seed = int(hashlib.sha256(prompt.encode(\"utf-8\")).hexdigest()[:8], 16)\n",
    "    rng  = np.random.default_rng(seed)\n",
    "    primitives = list(primitive_to_term_mapping.keys())\n",
    "    traces = {p: rng.normal(0.0, sigma, size=T).astype(\"float32\") for p in primitives}\n",
    "\n",
    "    # 2) build a canonical lobe shape\n",
    "    q = kaiser_window(L=min(160, max(64, T//8)))\n",
    "\n",
    "    # 3) inject lobes from strong spans\n",
    "    span_hits = 0\n",
    "    for p, hits in primitive_to_term_mapping.items():\n",
    "        if not hits: \n",
    "            continue\n",
    "        # keep only strong spans\n",
    "        strong = [h for h in hits if float(h.get(\"score\",0.0)) >= tau_span]\n",
    "        if not strong:\n",
    "            continue\n",
    "\n",
    "        if fuse_per_primitive:\n",
    "            # one fused lobe per primitive (amplitude = max span score)\n",
    "            A = max(float(h[\"score\"]) for h in strong)\n",
    "            tc = np.mean([float(h.get(\"t_center\", 0.5)) for h in strong])\n",
    "            start = max(0, min(T - len(q), int(tc * (T - len(q)))))\n",
    "            traces[p][start:start+len(q)] += A * q\n",
    "            span_hits += 1\n",
    "        else:\n",
    "            # one lobe per span\n",
    "            for h in strong:\n",
    "                A  = float(h[\"score\"])\n",
    "                tc = float(h.get(\"t_center\", 0.5))\n",
    "                start = max(0, min(T - len(q), int(tc * (T - len(q)))))\n",
    "                traces[p][start:start+len(q)] += A * q\n",
    "                span_hits += 1\n",
    "\n",
    "    if span_hits == 0:\n",
    "        return {\n",
    "            \"decision\": \"ABSTAIN\",\n",
    "            \"sequence\": [],\n",
    "            \"accepted_peaks\": {},\n",
    "            \"notes\": {\"reason\": \"no_span_evidence\", \"tau_span\": tau_span, \"T\": T}\n",
    "        }\n",
    "\n",
    "    # 4) matched filter + parser\n",
    "    scores, nulls, peaks = matched_filter_scores(traces, q)\n",
    "    sequence, accepted = decide(scores, nulls, tau_rel=tau_rel, tau_abs=tau_abs)\n",
    "\n",
    "    return {\n",
    "        \"decision\": \"PASS\" if sequence else \"ABSTAIN\",\n",
    "        \"sequence\": sequence,\n",
    "        \"accepted_peaks\": accepted,\n",
    "        \"peaks\": peaks,  # optional: raw peak info\n",
    "        \"notes\": {\n",
    "            \"tau_span\": tau_span, \"tau_rel\": tau_rel, \"tau_abs\": tau_abs,\n",
    "            \"sigma\": sigma, \"T\": T, \"fused\": fuse_per_primitive\n",
    "        }\n",
    "    }\n",
    "\n",
    "# ---------- demo ----------\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    for k, test_prompt in enumerate(negative_test_seeds):\n",
    "        span_map = spans_from_prompt(test_prompt, prototypes, emb, tau_span=tau_span)\n",
    "        if(PRIMITIVE in span_map):    \n",
    "            primitive_to_term_mapping = {\n",
    "                \"deposit_asset\":  [],       \n",
    "                \"withdraw_asset\": [],\n",
    "                \"swap_asset\": [],\n",
    "                \"borrow_asset\": [],\n",
    "                \"repay_asset\": [],\n",
    "                \"stake_asset\": [],\n",
    "                \"unstake_asset\": [],\n",
    "                \"claim_rewards\": []\n",
    "            }\n",
    "\n",
    "            primitive_to_term_mapping[PRIMITIVE] = span_map[PRIMITIVE]\n",
    "            \n",
    "            audit = audit_from_span_map(\n",
    "                test_prompt,\n",
    "                primitive_to_term_mapping,\n",
    "                T=720, tau_span=0.55, tau_abs=0.50, tau_rel=0.60, sigma=0.02,\n",
    "                fuse_per_primitive=False\n",
    "            )\n",
    "            #print(json.dumps(audit, indent=2))\n",
    "            is_passed = audit['decision']\n",
    "            print(f'{k} {is_passed} / prompt: {test_prompt} / primitives: {list(span_map.keys())}')\n",
    "        else:\n",
    "            print(f'{k} ABSTAIN / prompt: {test_prompt}')\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c56855d-0869-4cee-96ed-894f97de9fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1784: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['claim_rewards', 'deposit_asset', 'deposit_asset',\n",
       "       'withdraw_asset', '', ''], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prompts = ['sing me a lullaby',\n",
    "                      'what’s the weather in NYC?',\n",
    "                      'open settings',\n",
    "                      'convert centimeters to inches',\n",
    "                      'swap seats with me',\n",
    "                      'hey wats going on']\n",
    "\n",
    "# mapper\n",
    "mapper = joblib.load(model_path)\n",
    "# test_prompts = _read_prompts_jsonl(args.prompts_jsonl)\n",
    "labeled_test_prompts = _read_labels_csv(args.labels_csv_pred)\n",
    "threshold = float(args.threshold)\n",
    "\n",
    "classes, probs = _predict_proba(mapper, test_prompts)\n",
    "\n",
    "top_idx = probs.argmax(axis=1)\n",
    "top_conf = probs.max(axis=1)\n",
    "fired = (top_conf >= threshold)\n",
    "preds = np.array([classes[i] for i in top_idx], dtype=object)\n",
    "pred_labels = np.where(fired, preds, \"\")\n",
    "pred_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169182a0-478a-432b-a651-5dca533eb4b4",
   "metadata": {},
   "source": [
    "## ChatGPT Fix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf633893-acd1-469a-a38b-30a03e164e28",
   "metadata": {},
   "source": [
    "### 0) seed terms + encoder + prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2a562464-a1c6-49ec-807a-232c9e17efb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 0: seed term bank (tight, unambiguous) =====\n",
    "TERM_BANK = {\n",
    "    \"deposit_asset\":  [\"deposit\", \"supply\", \"provide\"],\n",
    "    \"withdraw_asset\": [\"withdraw\", \"redeem\", \"unstow\"],\n",
    "    \"swap_asset\":     [\"swap\", \"convert\", \"trade\", \"exchange\"],\n",
    "    \"borrow_asset\":   [\"borrow\", \"draw\"],\n",
    "    \"repay_asset\":    [\"repay\", \"pay back\"],\n",
    "    \"stake_asset\":    [\"stake\", \"lock\", \"bond\"],\n",
    "    \"unstake_asset\":  [\"unstake\", \"unlock\", \"unbond\"],\n",
    "    \"claim_rewards\":  [\"claim\", \"harvest\", \"collect rewards\"],\n",
    "}\n",
    "PRIMS = list(TERM_BANK.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "48e6625e-4f7d-498d-ba0a-1e3f72f2df29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 1: SBERT encoder wrapper =====\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "class Emb:\n",
    "    def __init__(self, model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "        self._m = SentenceTransformer(model_name)\n",
    "    def encode(self, texts, normalize_embeddings=True, show_progress_bar=False):\n",
    "        return self._m.encode(\n",
    "            texts, normalize_embeddings=normalize_embeddings,\n",
    "            show_progress_bar=show_progress_bar\n",
    "        )\n",
    "    def encode_one(self, text, normalize_embeddings=True):\n",
    "        return self.encode([text], normalize_embeddings=normalize_embeddings)[0]\n",
    "\n",
    "emb = Emb()  # or Emb(\"sentence-transformers/all-mpnet-base-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1da90796-6c6e-4bd7-8b5f-63a33a51cfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 2: build primitive -> prototype vector (centroid over seed terms) =====\n",
    "def build_prototypes(term_bank: dict[str, list[str]], emb: Emb) -> dict[str, np.ndarray]:\n",
    "    protos = {}\n",
    "    for prim, terms in term_bank.items():\n",
    "        V = np.asarray(emb.encode(terms, normalize_embeddings=True))\n",
    "        protos[prim] = V.mean(axis=0)\n",
    "    return protos\n",
    "\n",
    "prototypes = build_prototypes(TERM_BANK, emb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9325c0c-8642-4875-a361-5a1276277a8d",
   "metadata": {},
   "source": [
    "## 1) spans_from_prompt (your style, dict-only return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "53f87e38-3c2c-4874-a5f5-f2e89c261fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 3: spans_from_prompt (dict-only return) =====\n",
    "import re\n",
    "\n",
    "_WORD = re.compile(r\"[a-z0-9]+(?:'[a-z0-9]+)?\")\n",
    "\n",
    "def _norm_tokens(txt: str) -> list[str]:\n",
    "    txt = txt.lower()\n",
    "    return _WORD.findall(txt)\n",
    "\n",
    "def _cosine(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    da = float(np.linalg.norm(a) + 1e-9)\n",
    "    db = float(np.linalg.norm(b) + 1e-9)\n",
    "    return float(np.dot(a, b) / (da * db))\n",
    "\n",
    "def spans_from_prompt(prompt: str,\n",
    "                      prototypes: dict[str, np.ndarray],\n",
    "                      emb: Emb,\n",
    "                      tau_span: float = 0.55,\n",
    "                      n_max: int = 5,\n",
    "                      topk_per_prim: int = 3):\n",
    "    \"\"\"\n",
    "    Returns: dict primitive -> [ {primitive, term, score, t_center, start, len}, ... ] (top-k per primitive)\n",
    "    \"\"\"\n",
    "    toks = _norm_tokens(prompt)\n",
    "    if not toks:\n",
    "        return {}\n",
    "\n",
    "    grams, meta = [], []   # meta holds (start, n, t_center)\n",
    "    for n in range(1, min(n_max, len(toks)) + 1):\n",
    "        for i in range(0, len(toks) - n + 1):\n",
    "            s = \" \".join(toks[i:i+n])\n",
    "            t_center = (i + n/2.0) / max(1.0, len(toks))\n",
    "            grams.append(s)\n",
    "            meta.append((i, n, t_center))\n",
    "\n",
    "    V = emb.encode(grams, normalize_embeddings=True, show_progress_bar=False)  # [M, D]\n",
    "\n",
    "    by_prim: dict[str, list[dict]] = {k: [] for k in prototypes.keys()}\n",
    "    for m, (i, n, t_center) in enumerate(meta):\n",
    "        v = V[m]\n",
    "        for prim, proto in prototypes.items():\n",
    "            sc = max(0.0, _cosine(v, proto))\n",
    "            if sc >= tau_span:\n",
    "                by_prim[prim].append({\n",
    "                    \"primitive\": prim,\n",
    "                    \"term\": grams[m],\n",
    "                    \"score\": round(sc, 4),\n",
    "                    \"t_center\": round(t_center, 4),\n",
    "                    \"start\": i,\n",
    "                    \"len\": n,\n",
    "                })\n",
    "\n",
    "    # keep top-k per primitive by score\n",
    "    for prim in list(by_prim.keys()):\n",
    "        arr = sorted(by_prim[prim], key=lambda x: x[\"score\"], reverse=True)[:topk_per_prim]\n",
    "        if arr:\n",
    "            by_prim[prim] = arr\n",
    "        else:\n",
    "            # drop empty lists to make downstream checks easy\n",
    "            by_prim.pop(prim, None)\n",
    "\n",
    "    return by_prim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f4a0ff-0355-49b6-a685-a8132142807b",
   "metadata": {},
   "source": [
    "### 2) audit wrapper (robust to dict-only or (dict, meta) variants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ecfcdc9b-c47f-44ee-906f-02176594b651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 4: audit_prompt_with_spans (robust wrapper) =====\n",
    "def audit_prompt_with_spans(prompt: str,\n",
    "                            prototypes: dict[str, np.ndarray],\n",
    "                            emb: Emb,\n",
    "                            tau_span: float = 0.55,\n",
    "                            rel_margin: float = 0.06):\n",
    "    \"\"\"\n",
    "    Uses spans_from_prompt to produce:\n",
    "      - best_primitive: lexical 'winner' (requires tau + small relative margin)\n",
    "      - scores: top-score per primitive (0 if none)\n",
    "      - spans: raw span map from spans_from_prompt\n",
    "      - rel_margin: best - second best score\n",
    "    Works whether spans_from_prompt returns dict or (dict, meta).\n",
    "    \"\"\"\n",
    "    out = spans_from_prompt(prompt, prototypes, emb, tau_span=tau_span)\n",
    "    if isinstance(out, tuple):\n",
    "        span_map, meta = out\n",
    "    else:\n",
    "        span_map, meta = out, {}\n",
    "\n",
    "    # top score per primitive (ensure we cover all prototypes, even if absent in span_map)\n",
    "    scores = {}\n",
    "    for prim in prototypes.keys():\n",
    "        lst = span_map.get(prim, [])\n",
    "        scores[prim] = (lst[0][\"score\"] if lst else 0.0)\n",
    "\n",
    "    ordered = sorted(scores.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    best_prim, best_sc = ordered[0]\n",
    "    second_sc = ordered[1][1] if len(ordered) > 1 else 0.0\n",
    "    winner = best_prim if (best_sc >= tau_span and (best_sc - second_sc) >= rel_margin) else None\n",
    "\n",
    "    return {\n",
    "        \"best_primitive\": winner,\n",
    "        \"scores\": scores,\n",
    "        \"spans\": span_map,\n",
    "        \"rel_margin\": best_sc - second_sc,\n",
    "        \"meta\": meta,\n",
    "        \"params\": {\"tau_span\": tau_span, \"rel_margin\": rel_margin},\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c80172-4871-4d6c-ae93-284f0f64866a",
   "metadata": {},
   "source": [
    "### 3) opposite-primitive veto (kills tautologies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "19f3146e-2f85-420b-8b56-cd6209f812fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 5: opposite/veto helpers =====\n",
    "OPPOSITE = {\n",
    "    \"deposit_asset\": \"withdraw_asset\",\n",
    "    \"withdraw_asset\": \"deposit_asset\",\n",
    "    \"stake_asset\": \"unstake_asset\",\n",
    "    \"unstake_asset\": \"stake_asset\",\n",
    "    \"borrow_asset\": \"repay_asset\",\n",
    "    \"repay_asset\": \"borrow_asset\",\n",
    "    # claim_rewards has no strict opposite in this simple map\n",
    "}\n",
    "\n",
    "def should_veto(mapper_top1: str | None, audit_best: str | None) -> bool:\n",
    "    if not mapper_top1 or not audit_best:\n",
    "        return False\n",
    "    return OPPOSITE.get(mapper_top1) == audit_best\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c62af9-52a5-40fa-b552-b720fd54bde5",
   "metadata": {},
   "source": [
    "### 4) fuse with mapper (single call to get final decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "71ef697b-69b3-48cf-90cb-275a2a024b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 6: fuse_decision (mapper + spans audit) =====\n",
    "import joblib\n",
    "\n",
    "def load_mapper(path=\".artifacts/defi_mapper.joblib\"):\n",
    "    return joblib.load(path)\n",
    "\n",
    "def mapper_top1_label(mapper, prompt: str):\n",
    "    # generic scikit-like pipeline\n",
    "    if hasattr(mapper, \"predict_proba\"):\n",
    "        probs = mapper.predict_proba([prompt])[0]\n",
    "        classes = list(getattr(mapper, \"classes_\", PRIMS))\n",
    "        top_idx = int(np.argmax(probs))\n",
    "        return classes[top_idx], float(probs[top_idx])\n",
    "    else:\n",
    "        lab = mapper.predict([prompt])[0]\n",
    "        return str(lab), 1.0\n",
    "\n",
    "def fuse_decision(prompt: str,\n",
    "                  mapper,\n",
    "                  prototypes: dict[str, np.ndarray],\n",
    "                  emb: Emb,\n",
    "                  conf_thr: float = 0.70,\n",
    "                  tau_span: float = 0.55,\n",
    "                  rel_margin: float = 0.06):\n",
    "    m_top, m_conf = mapper_top1_label(mapper, prompt)\n",
    "    fired = bool(m_conf >= conf_thr)\n",
    "\n",
    "    audit = audit_prompt_with_spans(prompt, prototypes, emb, tau_span=tau_span, rel_margin=rel_margin)\n",
    "    a_best = audit[\"best_primitive\"]\n",
    "\n",
    "    if not fired:\n",
    "        return {\n",
    "            \"prompt\": prompt,\n",
    "            \"decision\": \"abstain_non_exec\",\n",
    "            \"reason\": \"low_conf_mapper\",\n",
    "            \"mapper\": {\"top\": m_top, \"conf\": m_conf},\n",
    "            \"audit\": audit,\n",
    "        }\n",
    "\n",
    "    if should_veto(m_top, a_best):\n",
    "        return {\n",
    "            \"prompt\": prompt,\n",
    "            \"decision\": \"reject\",\n",
    "            \"reason\": f\"tautology_veto:{m_top}_vs_{a_best}\",\n",
    "            \"mapper\": {\"top\": m_top, \"conf\": m_conf},\n",
    "            \"audit\": audit,\n",
    "        }\n",
    "\n",
    "    # optional: require lexical alignment when audit is strong\n",
    "    if a_best and a_best != m_top:\n",
    "        return {\n",
    "            \"prompt\": prompt,\n",
    "            \"decision\": \"reject\",\n",
    "            \"reason\": f\"audit_mismatch:{m_top}_vs_{a_best}\",\n",
    "            \"mapper\": {\"top\": m_top, \"conf\": m_conf},\n",
    "            \"audit\": audit,\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"prompt\": prompt,\n",
    "        \"decision\": \"approve\",\n",
    "        \"mapper\": {\"top\": m_top, \"conf\": m_conf},\n",
    "        \"audit\": audit,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0371eb82-ffb5-465f-9b82-f499f189da21",
   "metadata": {},
   "source": [
    "### 5) quick smoke (copy/paste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a899ded2-1830-4fc9-a20a-c2249c33efba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1784: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1784: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1784: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1784: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1784: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1784: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "approve — deposit 10 ETH into aave\n",
      "approve — withdraw 5 ETH\n",
      "approve — swap 2 ETH for USDC on uniswap — minimize gas\n",
      "abstain_non_exec — check balance\n",
      "  reason: low_conf_mapper\n",
      "approve — repay 300 USDC to aave\n",
      "approve — unstake 1000 USDC from rocket pool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1784: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "approve — provide 4569.792 OP to balancer on arbitrum — asap\n",
      "abstain_non_exec — swap 991.2209 WETH to MATIC on compound\n",
      "  reason: low_conf_mapper\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1784: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1784: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstain_non_exec — unstake and take out 1941.4165 LINK — use normal gas\n",
      "  reason: low_conf_mapper\n",
      "abstain_non_exec — supply 231.3364 USDC — safe mode\n",
      "  reason: low_conf_mapper\n",
      "abstain_non_exec — withdraw 2728.1894 ARB — asap\n",
      "  reason: low_conf_mapper\n",
      "approve — open a loan for 1495.415 SOL — asap\n",
      "abstain_non_exec — sing me a lullaby\n",
      "  reason: low_conf_mapper\n",
      "reject — convert centimeters to inches\n",
      "  reason: audit_mismatch:withdraw_asset_vs_swap_asset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1784: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1784: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1784: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1784: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1784: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 7: quick smoke =====\n",
    "PRIMS = list(prototypes.keys())\n",
    "mapper = joblib.load(model_path)\n",
    "tests = [\n",
    "    \"deposit 10 ETH into aave\",\n",
    "    \"withdraw 5 ETH\",\n",
    "    \"swap 2 ETH for USDC on uniswap — minimize gas\",\n",
    "    \"check balance\",\n",
    "    \"repay 300 USDC to aave\",\n",
    "    \"unstake 1000 USDC from rocket pool\",\n",
    "    \"provide 4569.792 OP to balancer on arbitrum — asap\",\n",
    "    \"swap 991.2209 WETH to MATIC on compound\",\n",
    "    \"unstake and take out 1941.4165 LINK — use normal gas\",\n",
    "    \"supply 231.3364 USDC — safe mode\",\n",
    "    \"withdraw 2728.1894 ARB — asap\",\n",
    "    \"open a loan for 1495.415 SOL — asap\",\n",
    "    \"sing me a lullaby\",\n",
    "    \"convert centimeters to inches\"\n",
    "]\n",
    "for p in tests:\n",
    "    out = fuse_decision(p, mapper, prototypes, emb, conf_thr=0.70, tau_span=0.55, rel_margin=0.06)\n",
    "    print(out[\"decision\"], \"—\", p)\n",
    "    if out[\"decision\"] != \"approve\":\n",
    "        print(\"  reason:\", out.get(\"reason\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
