{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad9b562a-6ea1-440c-8be1-f67d677b7c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd =  os.getcwd().replace(\"notebooks/research\",\"\")\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4c58a1c2-63ef-40f0-b1ec-d8544c11d428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== ARC WDD — notebook tester (mirrors DeFi WDD flow) ====\n",
    "import os, json, math, random, numpy as np, pandas as pd\n",
    "import torch, torch.nn as nn\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------- 0) Data ----------\n",
    "CSV = \"tests/fixtures/arc/arc_mapper_labeled.csv\"  # <-- change if yours is elsewhere\n",
    "df = pd.read_csv(CSV)\n",
    "assert {\"grid\",\"label\"}.issubset(df.columns), \"CSV must have grid,label columns\"\n",
    "\n",
    "def load_grid(cell):\n",
    "    if isinstance(cell, str): return np.asarray(json.loads(cell), dtype=int)\n",
    "    return np.asarray(cell, dtype=int)\n",
    "\n",
    "LABELS = sorted(df[\"label\"].unique())\n",
    "print(\"labels:\", LABELS, \"n=\", len(df))\n",
    "\n",
    "# ---------- 1) Tiny ARC encoder (H×W grid -> per-cell hidden states) ----------\n",
    "# Inputs: one-hot color (10) + (x,y) pos sin/cos (8)  => 18 channels\n",
    "# Tiny CNN -> [B, D, H, W] ; we'll flatten per cell to [T,H]\n",
    "class TinyARCEncoder(nn.Module):\n",
    "    def __init__(self, in_ch=18, hid=64, depth=3):\n",
    "        super().__init__()\n",
    "        ch = hid\n",
    "        layers = [nn.Conv2d(in_ch, ch, 3, padding=1), nn.ReLU(inplace=True)]\n",
    "        for _ in range(depth-1):\n",
    "            layers += [nn.Conv2d(ch, ch, 3, padding=1), nn.ReLU(inplace=True)]\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        # x: [B, C, H, W] -> [B, D, H, W]\n",
    "        return self.net(x)\n",
    "\n",
    "def posenc_xy(H, W):\n",
    "    # simple sin/cos pe (4 per axis = 8 total)\n",
    "    ys, xs = np.meshgrid(np.arange(H), np.arange(W), indexing=\"ij\")\n",
    "    ys = ys / max(1,H-1); xs = xs / max(1,W-1)\n",
    "    freqs = np.array([1.0, 2.0, 4.0, 8.0], dtype=float)\n",
    "    pe = []\n",
    "    for f in freqs:\n",
    "        pe.append(np.sin(2*math.pi*f*xs)[None,:,:])\n",
    "        pe.append(np.cos(2*math.pi*f*xs)[None,:,:])\n",
    "    for f in freqs:\n",
    "        pe.append(np.sin(2*math.pi*f*ys)[None,:,:])\n",
    "        pe.append(np.cos(2*math.pi*f*ys)[None,:,:])\n",
    "    return np.vstack(pe).astype(np.float32)  # [8,H,W]\n",
    "\n",
    "def grid_to_tensor(g):\n",
    "    g = np.asarray(g, dtype=int)\n",
    "    H,W = g.shape\n",
    "    # color one-hot (10)\n",
    "    oh = np.zeros((10,H,W), dtype=np.float32)\n",
    "    idx = np.clip(g, 0, 9)\n",
    "    for c in range(10): oh[c] = (idx==c).astype(np.float32)\n",
    "    pe = posenc_xy(H,W)  # [8,H,W]\n",
    "    x = np.vstack([oh, pe])  # [18,H,W]\n",
    "    return torch.from_numpy(x[None])  # [1,18,H,W]\n",
    "\n",
    "ENC_IN_CH  = 26   # 10 color one-hot + 16 pos-enc (x/y, 4 freqs, sin+cos)\n",
    "ENC_HID    = 64\n",
    "ARC_ENCODER = TinyARCEncoder(in_ch=ENC_IN_CH, hid=ENC_HID, depth=3).eval()\n",
    "\n",
    "@torch.no_grad()\n",
    "def encode_grid(g):\n",
    "    x = grid_to_tensor(g)\n",
    "    h = ARC_ENCODER(x)          # [1,D,H,W]\n",
    "    D,H,W = h.shape[1], h.shape[2], h.shape[3]\n",
    "    T = H*W\n",
    "    return h.view(1, D, T).permute(0,2,1).squeeze(0).cpu().float().numpy()  # [T,D]\n",
    "\n",
    "# ---------- 2) PCA warp H->3 ----------\n",
    "def fit_token_warp(mats, d=3, whiten=True):\n",
    "    X = np.vstack(mats); mu = X.mean(0); Xc = X - mu\n",
    "    U,S,Vt = np.linalg.svd(Xc, full_matrices=False)\n",
    "    pcs = Vt[:d,:]; Y = Xc @ pcs.T\n",
    "    scales = Y.std(0, ddof=1) + 1e-8 if whiten else np.ones(d, float)\n",
    "    return {\"mean\": mu.astype(np.float32), \"pcs\": pcs.astype(np.float32), \"scales\": scales.astype(np.float32)}\n",
    "\n",
    "def apply_token_warp(Z, warp):\n",
    "    Y = (Z - warp[\"mean\"]) @ warp[\"pcs\"].T\n",
    "    return Y / (warp[\"scales\"] + 1e-8)\n",
    "\n",
    "def traces_from_grid(grid, warp):\n",
    "    Z  = encode_grid(grid)           # [T,H]\n",
    "    Yw = apply_token_warp(Z, warp)   # [T,3]\n",
    "    return [Yw[:,0], Yw[:,1], Yw[:,2]]\n",
    "\n",
    "# ---------- 3) NGF: smoothing, parser, matched filter, priors ----------\n",
    "from ngeodesic.core.parser import moving_average, geodesic_parse_with_prior\n",
    "from ngeodesic.core.matched_filter import half_sine_proto, nxcorr\n",
    "from ngeodesic.core.funnel_profile import fit_radial_profile, analytic_core_template, blend_profiles, priors_from_profile, attach_projection_info\n",
    "\n",
    "def adaptive_windows_short(T: int):\n",
    "    \"\"\"Smaller template + tighter smoother to keep peaks sharp and avoid flattening.\"\"\"\n",
    "    proto_w = max(15, min(int(0.45*T), 41))\n",
    "    sigma   = max(3,  min(int(T/10), 7))\n",
    "    return sigma, proto_w\n",
    "def decide_arc(grid, guess_label=None, *, family_only=True):\n",
    "    traces = traces_from_grid(grid, warp)\n",
    "\n",
    "    if guess_label is not None and family_only:\n",
    "        pr = priors[guess_label]  # <-- ensure this uses guess_label\n",
    "        ok, info = wdd_prior_pass_scored(\n",
    "            traces, pr,\n",
    "            z_min=1.3, rel_floor=0.45,\n",
    "            alpha=0.14, beta_s=0.50, q_s=1.8,\n",
    "            null_K=30\n",
    "        )\n",
    "        return ok, {**info, \"which_prior\": guess_label}\n",
    "    \n",
    "    # otherwise evaluate all priors with margin (or swap to per_prior_thresh version)\n",
    "    # ok, info = decide_arc_with_margins(\n",
    "    #     grid, warp, priors,\n",
    "    #     z_min=1.3, rel_floor=0.45,\n",
    "    #     alpha=0.14, beta_s=0.50, q_s=1.8,\n",
    "    #     delta_margin=0.06\n",
    "    # )\n",
    "    ok, info = decide_arc_with_margins_per_prior(\n",
    "        grid, warp, priors, per_prior_thresh, delta_margin=0.10\n",
    "    )\n",
    "    return ok, info\n",
    "\n",
    "\n",
    "\n",
    "N_TEST_PER = 6\n",
    "tests = []\n",
    "for lab in LABELS:\n",
    "    rows = df[df.label==lab].sample(min(N_TEST_PER, (df.label==lab).sum()), random_state=123)\n",
    "    for _, r in rows.iterrows():\n",
    "        tests.append((lab, load_grid(r.grid)))\n",
    "\n",
    "print(f\"{'label':<18} | prior  | keep | sigma | proto_w | which_prior\")\n",
    "print(\"-\"*80)\n",
    "for lab, g in tests:\n",
    "    ok, info = decide_arc(g, guess_label=lab)   # evaluate against its own family prior\n",
    "    keep_str = \",\".join(info.get(\"keep\",[])) if info.get(\"keep\") else \"-\"\n",
    "    sig = info.get(\"sigma\") if info.get(\"sigma\") is not None else \"-\"\n",
    "    pw  = info.get(\"proto_w\") if info.get(\"proto_w\") is not None else \"-\"\n",
    "    print(f\"{lab:<18} | {('PASS' if ok else 'ABSTAIN'):>6} | {keep_str:^4} | {sig:^5} | {pw:^7} | {info.get('which_prior','-')}\")\n",
    "\n",
    "# Optional: quick sanity on cross-prior robustness (try the \"wrong\" prior)\n",
    "print(\"\\nCross-prior sanity (first 8 rows):\")\n",
    "for i, (lab, g) in enumerate(tests[:8]):\n",
    "    wrong = [x for x in LABELS if x!=lab][0]\n",
    "    ok, info = decide_arc(g, guess_label=wrong)\n",
    "    print(f\"{lab:>18} vs {wrong:<18} -> {'PASS' if ok else 'ABSTAIN'}\")\n",
    "\n",
    "def _mf_fallback_pass(traces, floor=0.18):\n",
    "    \"\"\"Optional fallback: if prior is borderline but MF peak is decent, accept.\"\"\"\n",
    "    T = len(traces[0]); proto_w = max(15, min(int(0.45*T), 41))\n",
    "    return (_smax_over_channels(traces, proto_w) >= floor)\n",
    "\n",
    "\n",
    "# NOTE: If your file defines build_priors_feature_MFpeak, consider tightening its inner smoothing/window:\n",
    "#   k_smooth = min(9, max(3, T//8))\n",
    "#   w_adapt  = min(proto_w, max(15, int(0.5*T)))\n",
    "# NOTE: When deriving per_prior_thresh from a holdout, prefer the 0.80 quantile with larger null_K (>=128).\n",
    "# Example:\n",
    "#   z_min = float(np.quantile([z for z in zs if np.isfinite(z)], 0.80))\n",
    "#   per_prior_thresh[lab] = max(1.2, min(z_min, 3.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ec063b81-a609-4ad6-a4c1-a749b4e4b283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: ['flip_h', 'flip_v', 'rot90'] n= 1000\n",
      "label              | prior  | keep | sigma | proto_w | which_prior\n",
      "--------------------------------------------------------------------------------\n",
      "flip_h             |   PASS | 1,2  |   7   |   41    | flip_h\n",
      "flip_h             | ABSTAIN |  1   |   7   |   41    | flip_h\n",
      "flip_h             | ABSTAIN | 1,2  |   7   |   41    | flip_h\n",
      "flip_h             | ABSTAIN | 1,2  |   7   |   41    | flip_h\n",
      "flip_h             | ABSTAIN | 1,2  |   7   |   41    | flip_h\n",
      "flip_h             | ABSTAIN |  1   |   7   |   41    | flip_h\n",
      "flip_v             | ABSTAIN |  2   |   7   |   41    | flip_v\n",
      "flip_v             | ABSTAIN | 1,2  |   7   |   41    | flip_v\n",
      "flip_v             | ABSTAIN |  2   |   7   |   41    | flip_v\n",
      "flip_v             | ABSTAIN | 1,2  |   7   |   41    | flip_v\n",
      "flip_v             | ABSTAIN |  1   |   7   |   41    | flip_v\n",
      "flip_v             | ABSTAIN |  -   |   7   |   41    | flip_v\n",
      "rot90              | ABSTAIN |  1   |   7   |   41    | rot90\n",
      "rot90              | ABSTAIN |  1   |   7   |   41    | rot90\n",
      "rot90              | ABSTAIN |  2   |   7   |   41    | rot90\n",
      "rot90              | ABSTAIN |  -   |   7   |   41    | rot90\n",
      "rot90              | ABSTAIN |  -   |   7   |   41    | rot90\n",
      "rot90              | ABSTAIN |  1   |   7   |   41    | rot90\n",
      "\n",
      "Cross-prior sanity (first 8 rows):\n",
      "            flip_h vs flip_v             -> PASS\n",
      "            flip_h vs flip_v             -> ABSTAIN\n",
      "            flip_h vs flip_v             -> ABSTAIN\n",
      "            flip_h vs flip_v             -> ABSTAIN\n",
      "            flip_h vs flip_v             -> ABSTAIN\n",
      "            flip_h vs flip_v             -> ABSTAIN\n",
      "            flip_v vs flip_h             -> ABSTAIN\n",
      "            flip_v vs flip_h             -> ABSTAIN\n"
     ]
    }
   ],
   "source": [
    "# ==== ARC WDD — notebook tester (mirrors DeFi WDD flow) ====\n",
    "import os, json, math, random, numpy as np, pandas as pd\n",
    "import torch, torch.nn as nn\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------- 0) Data ----------\n",
    "CSV = \"tests/fixtures/arc/arc_mapper_labeled.csv\"  # <-- change if yours is elsewhere\n",
    "df = pd.read_csv(CSV)\n",
    "assert {\"grid\",\"label\"}.issubset(df.columns), \"CSV must have grid,label columns\"\n",
    "\n",
    "def load_grid(cell):\n",
    "    if isinstance(cell, str): return np.asarray(json.loads(cell), dtype=int)\n",
    "    return np.asarray(cell, dtype=int)\n",
    "\n",
    "LABELS = sorted(df[\"label\"].unique())\n",
    "print(\"labels:\", LABELS, \"n=\", len(df))\n",
    "\n",
    "# ---------- 1) Tiny ARC encoder (H×W grid -> per-cell hidden states) ----------\n",
    "# Inputs: one-hot color (10) + (x,y) pos sin/cos (8)  => 18 channels\n",
    "# Tiny CNN -> [B, D, H, W] ; we'll flatten per cell to [T,H]\n",
    "class TinyARCEncoder(nn.Module):\n",
    "    def __init__(self, in_ch=18, hid=64, depth=3):\n",
    "        super().__init__()\n",
    "        ch = hid\n",
    "        layers = [nn.Conv2d(in_ch, ch, 3, padding=1), nn.ReLU(inplace=True)]\n",
    "        for _ in range(depth-1):\n",
    "            layers += [nn.Conv2d(ch, ch, 3, padding=1), nn.ReLU(inplace=True)]\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        # x: [B, C, H, W] -> [B, D, H, W]\n",
    "        return self.net(x)\n",
    "\n",
    "def posenc_xy(H, W):\n",
    "    # simple sin/cos pe (4 per axis = 8 total)\n",
    "    ys, xs = np.meshgrid(np.arange(H), np.arange(W), indexing=\"ij\")\n",
    "    ys = ys / max(1,H-1); xs = xs / max(1,W-1)\n",
    "    freqs = np.array([1.0, 2.0, 4.0, 8.0], dtype=float)\n",
    "    pe = []\n",
    "    for f in freqs:\n",
    "        pe.append(np.sin(2*math.pi*f*xs)[None,:,:])\n",
    "        pe.append(np.cos(2*math.pi*f*xs)[None,:,:])\n",
    "    for f in freqs:\n",
    "        pe.append(np.sin(2*math.pi*f*ys)[None,:,:])\n",
    "        pe.append(np.cos(2*math.pi*f*ys)[None,:,:])\n",
    "    return np.vstack(pe).astype(np.float32)  # [8,H,W]\n",
    "\n",
    "def grid_to_tensor(g):\n",
    "    g = np.asarray(g, dtype=int)\n",
    "    H,W = g.shape\n",
    "    # color one-hot (10)\n",
    "    oh = np.zeros((10,H,W), dtype=np.float32)\n",
    "    idx = np.clip(g, 0, 9)\n",
    "    for c in range(10): oh[c] = (idx==c).astype(np.float32)\n",
    "    pe = posenc_xy(H,W)  # [8,H,W]\n",
    "    x = np.vstack([oh, pe])  # [18,H,W]\n",
    "    return torch.from_numpy(x[None])  # [1,18,H,W]\n",
    "\n",
    "ENC_IN_CH  = 26   # 10 color one-hot + 16 pos-enc (x/y, 4 freqs, sin+cos)\n",
    "ENC_HID    = 64\n",
    "ARC_ENCODER = TinyARCEncoder(in_ch=ENC_IN_CH, hid=ENC_HID, depth=3).eval()\n",
    "\n",
    "@torch.no_grad()\n",
    "def encode_grid(g):\n",
    "    x = grid_to_tensor(g)\n",
    "    h = ARC_ENCODER(x)          # [1,D,H,W]\n",
    "    D,H,W = h.shape[1], h.shape[2], h.shape[3]\n",
    "    T = H*W\n",
    "    return h.view(1, D, T).permute(0,2,1).squeeze(0).cpu().float().numpy()  # [T,D]\n",
    "\n",
    "# ---------- 2) PCA warp H->3 ----------\n",
    "def fit_token_warp(mats, d=3, whiten=True):\n",
    "    X = np.vstack(mats); mu = X.mean(0); Xc = X - mu\n",
    "    U,S,Vt = np.linalg.svd(Xc, full_matrices=False)\n",
    "    pcs = Vt[:d,:]; Y = Xc @ pcs.T\n",
    "    scales = Y.std(0, ddof=1) + 1e-8 if whiten else np.ones(d, float)\n",
    "    return {\"mean\": mu.astype(np.float32), \"pcs\": pcs.astype(np.float32), \"scales\": scales.astype(np.float32)}\n",
    "\n",
    "def apply_token_warp(Z, warp):\n",
    "    Y = (Z - warp[\"mean\"]) @ warp[\"pcs\"].T\n",
    "    return Y / (warp[\"scales\"] + 1e-8)\n",
    "\n",
    "def traces_from_grid(grid, warp):\n",
    "    Z  = encode_grid(grid)           # [T,H]\n",
    "    Yw = apply_token_warp(Z, warp)   # [T,3]\n",
    "    return [Yw[:,0], Yw[:,1], Yw[:,2]]\n",
    "\n",
    "# ---------- 3) NGF: smoothing, parser, matched filter, priors ----------\n",
    "from ngeodesic.core.parser import moving_average, geodesic_parse_with_prior\n",
    "from ngeodesic.core.matched_filter import half_sine_proto, nxcorr\n",
    "from ngeodesic.core.funnel_profile import fit_radial_profile, analytic_core_template, blend_profiles, priors_from_profile, attach_projection_info\n",
    "\n",
    "def adaptive_windows_short(T: int):\n",
    "    \"\"\"Smaller template + tighter smoother to keep peaks sharp and avoid flattening.\"\"\"\n",
    "    proto_w = max(15, min(int(0.45*T), 41))\n",
    "    sigma   = max(3,  min(int(T/10), 7))\n",
    "    return sigma, proto_w\n",
    "def decide_arc(grid, guess_label=None, *, family_only=True):\n",
    "    traces = traces_from_grid(grid, warp)\n",
    "\n",
    "    if guess_label is not None and family_only:\n",
    "        pr = priors[guess_label]  # <-- ensure this uses guess_label\n",
    "        ok, info = wdd_prior_pass_scored(\n",
    "            traces, pr,\n",
    "            z_min=1.3, rel_floor=0.45,\n",
    "            alpha=0.14, beta_s=0.50, q_s=1.8,\n",
    "            null_K=30\n",
    "        )\n",
    "        return ok, {**info, \"which_prior\": guess_label}\n",
    "    \n",
    "    # otherwise evaluate all priors with margin (or swap to per_prior_thresh version)\n",
    "    # ok, info = decide_arc_with_margins(\n",
    "    #     grid, warp, priors,\n",
    "    #     z_min=1.3, rel_floor=0.45,\n",
    "    #     alpha=0.14, beta_s=0.50, q_s=1.8,\n",
    "    #     delta_margin=0.06\n",
    "    # )\n",
    "    ok, info = decide_arc_with_margins_per_prior(\n",
    "        grid, warp, priors, per_prior_thresh, delta_margin=0.10\n",
    "    )\n",
    "    return ok, info\n",
    "\n",
    "\n",
    "\n",
    "N_TEST_PER = 6\n",
    "tests = []\n",
    "for lab in LABELS:\n",
    "    rows = df[df.label==lab].sample(min(N_TEST_PER, (df.label==lab).sum()), random_state=123)\n",
    "    for _, r in rows.iterrows():\n",
    "        tests.append((lab, load_grid(r.grid)))\n",
    "\n",
    "print(f\"{'label':<18} | prior  | keep | sigma | proto_w | which_prior\")\n",
    "print(\"-\"*80)\n",
    "for lab, g in tests:\n",
    "    ok, info = decide_arc(g, guess_label=lab)   # evaluate against its own family prior\n",
    "    keep_str = \",\".join(info.get(\"keep\",[])) if info.get(\"keep\") else \"-\"\n",
    "    sig = info.get(\"sigma\") if info.get(\"sigma\") is not None else \"-\"\n",
    "    pw  = info.get(\"proto_w\") if info.get(\"proto_w\") is not None else \"-\"\n",
    "    print(f\"{lab:<18} | {('PASS' if ok else 'ABSTAIN'):>6} | {keep_str:^4} | {sig:^5} | {pw:^7} | {info.get('which_prior','-')}\")\n",
    "\n",
    "# Optional: quick sanity on cross-prior robustness (try the \"wrong\" prior)\n",
    "print(\"\\nCross-prior sanity (first 8 rows):\")\n",
    "for i, (lab, g) in enumerate(tests[:8]):\n",
    "    wrong = [x for x in LABELS if x!=lab][0]\n",
    "    ok, info = decide_arc(g, guess_label=wrong)\n",
    "    print(f\"{lab:>18} vs {wrong:<18} -> {'PASS' if ok else 'ABSTAIN'}\")\n",
    "\n",
    "def _mf_fallback_pass(traces, floor=0.18):\n",
    "    \"\"\"Optional fallback: if prior is borderline but MF peak is decent, accept.\"\"\"\n",
    "    T = len(traces[0]); proto_w = max(15, min(int(0.45*T), 41))\n",
    "    return (_smax_over_channels(traces, proto_w) >= floor)\n",
    "\n",
    "\n",
    "# NOTE: If your file defines build_priors_feature_MFpeak, consider tightening its inner smoothing/window:\n",
    "#   k_smooth = min(9, max(3, T//8))\n",
    "#   w_adapt  = min(proto_w, max(15, int(0.5*T)))\n",
    "# NOTE: When deriving per_prior_thresh from a holdout, prefer the 0.80 quantile with larger null_K (>=128).\n",
    "# Example:\n",
    "#   z_min = float(np.quantile([z for z in zs if np.isfinite(z)], 0.80))\n",
    "#   per_prior_thresh[lab] = max(1.2, min(z_min, 3.0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
