{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05546405-4532-4cbb-a141-92858a357a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd =  os.getcwd().replace(\"notebooks/research\",\"\")\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d43cbe9b-e578-47cb-adb4-fae0dbbdf69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoders shim ready (SBERTEncoder + SBERTFeaturizer) and sys.path configured\n"
     ]
    }
   ],
   "source": [
    "# --- Robust notebook shim for legacy joblib artifacts expecting `encoders.*` ---\n",
    "import sys, types, numpy as np\n",
    "\n",
    "# Create/replace a lightweight 'encoders' module in sys.modules\n",
    "enc_mod = types.ModuleType(\"encoders\")\n",
    "\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "except Exception as e:\n",
    "    SentenceTransformer = None\n",
    "    print(\"NOTE: sentence-transformers not available:\", e)\n",
    "\n",
    "class _SBERTBase:\n",
    "    \"\"\"\n",
    "    Compat shim implementing the sklearn Transformer API expected by saved Pipelines.\n",
    "    Handles pickles that don't call __init__ and are missing attributes.\n",
    "    Provides both class names: SBERTEncoder and SBERTFeaturizer.\n",
    "    \"\"\"\n",
    "    # NOTE: __init__ might not be called during unpickle; use _ensure_attrs() everywhere.\n",
    "    def __init__(self, model=\"sentence-transformers/all-MiniLM-L6-v2\", **kwargs):\n",
    "        self.model_name = model\n",
    "        self._enc = None\n",
    "        self._kwargs = kwargs\n",
    "\n",
    "    def _ensure_attrs(self):\n",
    "        # Add any attributes that might be missing from legacy pickles\n",
    "        if not hasattr(self, \"model_name\") or self.model_name is None:\n",
    "            self.model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "        if not hasattr(self, \"_enc\"):\n",
    "            self._enc = None\n",
    "        if not hasattr(self, \"_kwargs\"):\n",
    "            self._kwargs = {}\n",
    "\n",
    "    def _ensure_encoder(self):\n",
    "        self._ensure_attrs()\n",
    "        if self._enc is None:\n",
    "            if SentenceTransformer is None:\n",
    "                raise RuntimeError(\n",
    "                    \"sentence-transformers not installed in this kernel; \"\n",
    "                    \"pip install sentence-transformers && restart kernel\"\n",
    "                )\n",
    "            self._enc = SentenceTransformer(self.model_name)\n",
    "\n",
    "    # sklearn API\n",
    "    def fit(self, X, y=None):\n",
    "        self._ensure_attrs()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        self._ensure_encoder()\n",
    "        return np.asarray(self._enc.encode(list(X), show_progress_bar=False))\n",
    "\n",
    "    # some older code may call .encode directly; alias it\n",
    "    def encode(self, X):\n",
    "        return self.transform(X)\n",
    "\n",
    "# Expose both legacy names on the encoders module\n",
    "class SBERTEncoder(_SBERTBase): ...\n",
    "class SBERTFeaturizer(_SBERTBase): ...\n",
    "\n",
    "enc_mod.SBERTEncoder = SBERTEncoder\n",
    "enc_mod.SBERTFeaturizer = SBERTFeaturizer\n",
    "sys.modules[\"encoders\"] = enc_mod\n",
    "\n",
    "# Make sure your package code is importable too (if needed)\n",
    "import pathlib\n",
    "if str(pathlib.Path(\"src\").resolve()) not in sys.path:\n",
    "    sys.path.append(str(pathlib.Path(\"src\").resolve()))\n",
    "print(\"encoders shim ready (SBERTEncoder + SBERTFeaturizer) and sys.path configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "add5fe41-7f49-4b22-a559-56f2bbd389af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: /Users/ian_moore/repos/micro-lm/.artifacts/defi_mapper.joblib\n",
      "Pipeline(steps=[('sbertencoder', <__main__.SBERTEncoder object at 0x3178fb370>),\n",
      "                ('calibratedclassifiercv',\n",
      "                 CalibratedClassifierCV(cv=3,\n",
      "                                        estimator=LogisticRegression(C=8.0,\n",
      "                                                                     class_weight='balanced',\n",
      "                                                                     max_iter=2000,\n",
      "                                                                     random_state=0),\n",
      "                                        method='isotonic'))])\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "def load_mapper():\n",
    "    for name in [\".artifacts/defi_mapper.joblib\", \".artifacts/defi_mapper_embed.joblib\"]:\n",
    "        p = Path(name).resolve()\n",
    "        if p.exists():\n",
    "            print(\"Loading:\", p.as_posix())\n",
    "            return joblib.load(p.as_posix())\n",
    "    raise FileNotFoundError(\"No mapper artifact found in .artifacts/\")\n",
    "\n",
    "pipe = load_mapper()\n",
    "print(pipe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b83c4e60-2c75-4703-8cdf-6b9c9e215a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1784: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: deposit_asset\n",
      "Top-3: [('deposit_asset', 1.0), ('borrow_asset', 0.0), ('claim_rewards', 0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1784: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "prompt = \"supply 7.0245 SOL to maker\"\n",
    "pred  = pipe.predict([prompt])[0]\n",
    "probs = pipe.predict_proba([prompt])[0]\n",
    "print(\"Predicted:\", pred)\n",
    "print(\"Top-3:\", sorted(zip(pipe.classes_, probs), key=lambda t: t[1], reverse=True)[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d64dc9-3144-450f-8220-719cb378e5bd",
   "metadata": {},
   "source": [
    "### 1) Imports (from ngeodesic.core)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d43297d1-21a0-4fe0-b825-bf08fd2bddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ngeodesic.core.pca_warp import pca3_and_warp\n",
    "from ngeodesic.core.parser import (\n",
    "    geodesic_parse_report,\n",
    "    geodesic_parse_with_prior,\n",
    "    geodesic_parse_report_conf,\n",
    ")\n",
    "from ngeodesic.core.matched_filter import half_sine_proto, nxcorr, null_threshold\n",
    "from ngeodesic.core.denoise import TemporalDenoiser\n",
    "from ngeodesic.core.energies import perpendicular_energy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9490bbf7-1b5b-4237-95ee-0e8d572df714",
   "metadata": {},
   "source": [
    "### 2) Get token-time hidden states (SBERT → Transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b40bb32e-09df-4575-bff9-28fea05f6bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "BASE = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "tok = AutoTokenizer.from_pretrained(BASE)\n",
    "mdl = AutoModel.from_pretrained(BASE, output_hidden_states=True).eval()\n",
    "\n",
    "def get_hidden_states(text: str, layer_offset: int = -4):\n",
    "    with torch.no_grad():\n",
    "        out = mdl(**tok(text, return_tensors=\"pt\"))\n",
    "    hs = out.hidden_states\n",
    "    k  = max(-(len(hs)-1), min(layer_offset, -1))  # clamp to valid non-embedding\n",
    "    return hs[k].squeeze(0).float().cpu().numpy()  # [T, H]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fbd019-8a35-4220-9331-09d6b96df118",
   "metadata": {},
   "source": [
    "### 3) Fit the Stage-11 PCA warp once, then apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac8540b2-e1aa-417d-954a-af0b9b5e1d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1784: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# (a) fit on a calibration batch\n",
    "cal_texts = [\n",
    "    \"supply 7.0245 SOL to maker\",\n",
    "    \"swap 10 ETH to USDC on uniswap\",\n",
    "    \"borrow 500 USDC with ETH collateral at 70% ltv\",\n",
    "]\n",
    "H = np.vstack([ get_hidden_states(t) for t in cal_texts ])   # (ΣT, H)\n",
    "proj = pca3_and_warp(H)  # -> dict(mean, pcs, scales, center)\n",
    "\n",
    "# (b) helper to apply the warp to a single prompt\n",
    "def apply_warp_to_text(text: str):\n",
    "    Z  = get_hidden_states(text)               # [T, H]\n",
    "    Y  = (Z - proj[\"mean\"]) @ proj[\"pcs\"].T    # [T, 3]\n",
    "    Yw = Y / (proj[\"scales\"] + 1e-8)           # whitened [T, 3]\n",
    "    return Yw\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bae770a-40a1-4762-b760-70b3b7857d61",
   "metadata": {},
   "source": [
    "### 4) Run the consolidated Stage-11 parser (no priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ea5c3b9-4524-4bf5-9c7a-2b1e629afa77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['0'], ['0'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"swap 10 ETH to USDC on uniswap\"\n",
    "text = \"supply 7.0245 SOL to maker\"\n",
    "Yw   = apply_warp_to_text(text)            # [T, 3]\n",
    "traces = [Yw[:,0], Yw[:,1], Yw[:,2]]       # three channels\n",
    "keep, order = geodesic_parse_report(traces, sigma=9, proto_width=160)\n",
    "keep, order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee56d165-22cc-489f-bcbc-79d7f3a4d420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'peak_idx': 80,\n",
       "  'z_res': 3.9721450552825166,\n",
       "  'z_raw': 4.24521414157031,\n",
       "  'z_cm': -0.5420038174461331,\n",
       "  'score': 5.670230711910641},\n",
       " '1': {'peak_idx': 78,\n",
       "  'z_res': -3.939877753110114,\n",
       "  'z_raw': 4.151917132317742,\n",
       "  'z_cm': -0.5420038174461331,\n",
       "  'score': -2.279110900183017},\n",
       " '2': {'peak_idx': 78,\n",
       "  'z_res': -2.948766826521682,\n",
       "  'z_raw': -2.7206724989994737,\n",
       "  'z_cm': -0.5420038174461331,\n",
       "  'score': -4.037035826121472}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep, order, dbg = geodesic_parse_report_conf(traces, sigma=9, proto_width=160)\n",
    "dbg[\"channels\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e1d8d9-fa7a-43bc-b591-b14013e3d974",
   "metadata": {},
   "source": [
    "### 5a) Fix A (simple & correct): use an identity 3D projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1434e314-eadc-43b4-bf73-56c70a21cf86",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'priors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 11\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mngeodesic\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparser\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m geodesic_parse_with_prior\n\u001b[1;32m      5\u001b[0m proj_feat \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m:   np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m3\u001b[39m),     \u001b[38;5;66;03m# (3,)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpcs\u001b[39m\u001b[38;5;124m\"\u001b[39m:    np\u001b[38;5;241m.\u001b[39meye(\u001b[38;5;241m3\u001b[39m),       \u001b[38;5;66;03m# (3,3)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscales\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;241m3\u001b[39m),      \u001b[38;5;66;03m# (3,)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcenter\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m]),  \u001b[38;5;66;03m# (2,) for (PC1,PC2)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m }\n\u001b[0;32m---> 11\u001b[0m priors \u001b[38;5;241m=\u001b[39m attach_projection_info(\u001b[43mpriors\u001b[49m, proj_feat)\n\u001b[1;32m     13\u001b[0m keep_p, order_p \u001b[38;5;241m=\u001b[39m geodesic_parse_with_prior(traces, priors\u001b[38;5;241m=\u001b[39mpriors, sigma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m, proto_width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m160\u001b[39m)\n\u001b[1;32m     14\u001b[0m keep_p, order_p\n",
      "\u001b[0;31mNameError\u001b[0m: name 'priors' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from ngeodesic.core.funnel_profile import attach_projection_info\n",
    "from ngeodesic.core.parser import geodesic_parse_with_prior\n",
    "\n",
    "proj_feat = {\n",
    "    \"mean\":   np.zeros(3),     # (3,)\n",
    "    \"pcs\":    np.eye(3),       # (3,3)\n",
    "    \"scales\": np.ones(3),      # (3,)\n",
    "    \"center\": np.array([0.0, 0.0]),  # (2,) for (PC1,PC2)\n",
    "}\n",
    "priors = attach_projection_info(priors, proj_feat)\n",
    "\n",
    "keep_p, order_p = geodesic_parse_with_prior(traces, priors=priors, sigma=9, proto_width=160)\n",
    "keep_p, order_p\n",
    "passed = bool(keep_p)\n",
    "passed\n",
    "\n",
    "keep_p, order_p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1898e591-6d02-44ac-a0f2-d0f90226c94a",
   "metadata": {},
   "source": [
    "### 5b) (optional): fit a feature-space 3D warp from calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84204a9-3b6f-4234-986b-dda366d8f63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ngeodesic.core.parser import moving_average  # for a quick _features clone here\n",
    "from ngeodesic.core.funnel_profile import attach_projection_info, priors_from_profile, fit_radial_profile, analytic_core_template, blend_profiles\n",
    "\n",
    "def _features(x, w=160):\n",
    "    pos   = np.maximum(0.0, x)\n",
    "    ma    = moving_average(pos, k=w)\n",
    "    j     = int(np.argmax(ma))\n",
    "    halfw = max(1, w // 2)\n",
    "    area  = float(pos[max(0, j - halfw): j + halfw + 1].sum())\n",
    "    meanp = float(pos.mean())\n",
    "    return np.array([j / max(1, len(x) - 1), area, meanp], dtype=float)  # (3,)\n",
    "\n",
    "# 1) collect 3D features per channel over calibration traces\n",
    "F = []  # will be (N,3)\n",
    "for t in cal_texts:\n",
    "    Yw = apply_warp_to_text(t)           # your [T,3] PCA channels over time\n",
    "    Sraw = [moving_average(Yw[:,i], k=9) for i in range(3)]\n",
    "    for ch in Sraw:\n",
    "        F.append(_features(ch, w=160))\n",
    "F = np.asarray(F, float)  # (N,3)\n",
    "\n",
    "# 2) fit a 3->3 whitened PCA in feature space\n",
    "mu = F.mean(axis=0)\n",
    "Fc = F - mu\n",
    "U, S, Vt = np.linalg.svd(Fc, full_matrices=False)\n",
    "pcs = Vt[:3, :]                 # (3,3)\n",
    "Y   = Fc @ pcs.T                # (N,3)\n",
    "scales = Y.std(axis=0, ddof=1) + 1e-8\n",
    "\n",
    "proj_feat = {\n",
    "    \"mean\":   mu,               # (3,)\n",
    "    \"pcs\":    pcs,              # (3,3)\n",
    "    \"scales\": scales,           # (3,)\n",
    "    \"center\": np.array([0.0, 0.0]),\n",
    "}\n",
    "priors = attach_projection_info(priors, proj_feat)\n",
    "\n",
    "# 3) proceed as before\n",
    "keep_p, order_p = geodesic_parse_with_prior(traces, priors=priors, sigma=9, proto_width=160)\n",
    "passed = bool(keep_p)\n",
    "passed\n",
    "\n",
    "keep_p, order_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181a044a-6205-432b-8a57-c99b60a8e48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ngeodesic.core.parser import geodesic_parse_with_prior  # Stage-11 parser\n",
    "\n",
    "def ngf_pass(traces, priors, *, sigma=9, proto_width=160, **knobs):\n",
    "    # knobs: z (abs floor), rel_floor, alpha (prior mix), beta_s (prior weight), q_s (prior sharpness)\n",
    "    keep, order = geodesic_parse_with_prior(\n",
    "        traces,\n",
    "        priors=priors,\n",
    "        sigma=sigma,\n",
    "        proto_width=proto_width,\n",
    "        **knobs,\n",
    "    )\n",
    "    return bool(keep), {\"keep\": keep, \"order\": order}\n",
    "\n",
    "passed, info = ngf_pass(traces, priors, z=2.2, rel_floor=0.70, alpha=0.05, beta_s=0.25, q_s=2.0)\n",
    "print(\"PASS\" if passed else \"ABSTAIN\", info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c606e9-8634-4277-8869-76c3fd79531a",
   "metadata": {},
   "source": [
    "### 6) Another example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "811e8130-ec42-42c5-acbd-f9bae94b3f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1'] ['1']\n",
      "{'0': {'peak_idx': 3, 'z_res': -1.820862128793049, 'z_raw': -1.3018366857035226, 'z_cm': -0.2763791283445771, 'score': -2.341596803074458}, '1': {'peak_idx': 5, 'z_res': 2.930356015228629, 'z_raw': 3.3201549913281116, 'z_cm': -0.2763791283445771, 'score': 4.258418011759874}, '2': {'peak_idx': 2, 'z_res': -1.93899111437996, 'z_raw': -1.9461171041916485, 'z_cm': -0.2763791283445771, 'score': -2.7174379560566195}}\n"
     ]
    }
   ],
   "source": [
    "text = \"borrow 500 USDC with ETH collateral at 70% ltv\"\n",
    "Yw   = apply_warp_to_text(text)            # [T, 3]\n",
    "traces = [Yw[:,0], Yw[:,1], Yw[:,2]]       # three channels\n",
    "\n",
    "T = len(traces[0])  # tokens in your PCA channel\n",
    "proto_w = max(11, min(int(0.6 * T), 61))  # 60% of T, clamped to [11, 61]\n",
    "sigma   = max(3, min(int(T / 10), 9))     # ~ T/10, clamped to [3, 9]\n",
    "\n",
    "keep, order, dbg = geodesic_parse_report_conf(traces, sigma=sigma, proto_width=proto_w)\n",
    "print(keep, order)\n",
    "print(dbg[\"channels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22527c8a-9842-45e8-b2c9-7c73739ed9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ngeodesic.core.parser import geodesic_parse_report_conf, geodesic_parse_with_prior\n",
    "\n",
    "def ngf_pass_from_traces(traces, *, priors=None, T=None):\n",
    "    T = T or len(traces[0])\n",
    "    proto_w = max(11, min(int(0.6 * T), 61))   # adapt to sequence length\n",
    "    sigma   = max(3,  min(int(T / 10), 9))\n",
    "\n",
    "    if priors is not None:\n",
    "        keep, order = geodesic_parse_with_prior(\n",
    "            traces, priors=priors, sigma=sigma, proto_width=proto_w,\n",
    "            # gentle, practical defaults for short prompts:\n",
    "            z=2.0, rel_floor=0.65, alpha=0.08, beta_s=0.35, q_s=2.0\n",
    "        )\n",
    "        return bool(keep), {\"keep\": keep, \"order\": order, \"sigma\": sigma, \"proto_w\": proto_w}\n",
    "\n",
    "    keep, order, dbg = geodesic_parse_report_conf(traces, sigma=sigma, proto_width=proto_w)\n",
    "    # simple rule: pass if any kept channel has score > 0 (the parser already applies relative gating)\n",
    "    passed = bool(keep) and any(dbg[\"channels\"][k][\"score\"] > 0 for k in keep)\n",
    "    return passed, {\"keep\": keep, \"order\": order, \"sigma\": sigma, \"proto_w\": proto_w, \"dbg\": dbg}\n",
    "\n",
    "def normalize_protocols(text: str) -> str:\n",
    "    # tiny lexicon with edit-distance fallback\n",
    "    vocab = [\"uniswap\",\"maker\",\"aave\",\"compound\",\"curve\"]\n",
    "    # fast path\n",
    "    for w in vocab:\n",
    "        if w in text.lower():\n",
    "            return text\n",
    "    # fallback: nearest vocab by Levenshtein (tiny threshold)\n",
    "    try:\n",
    "        import difflib\n",
    "        toks = text.split()\n",
    "        fixed = []\n",
    "        for t in toks:\n",
    "            cand = difflib.get_close_matches(t.lower(), vocab, n=1, cutoff=0.75)\n",
    "            fixed.append(cand[0] if cand else t)\n",
    "        return \" \".join(fixed)\n",
    "    except Exception:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4760a8cf-08a0-4702-965c-72ac51d7c0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ngeodesic.core.parser import geodesic_parse_report_conf, geodesic_parse_with_prior\n",
    "from ngeodesic.core.matched_filter import half_sine_proto, nxcorr, null_threshold\n",
    "import numpy as np\n",
    "\n",
    "def ngf_pass_strict(traces, *, priors=None, T=None, mapper=None, allow=(\"deposit\",\"swap\")):\n",
    "    T = T or len(traces[0])\n",
    "    if T < 6:\n",
    "        return False, {\"reason\":\"too_short\", \"T\": T}\n",
    "\n",
    "    proto_w = max(11, min(int(0.6 * T), 61))\n",
    "    sigma   = max(3,  min(int(T / 10), 9))\n",
    "\n",
    "    def _area_ok(x, j, w=proto_w, min_area=6.0):\n",
    "        pos = np.maximum(0.0, x); L=max(1,w//2)\n",
    "        return float(pos[max(0, j-L): j+L+1].sum()) >= min_area\n",
    "\n",
    "    if priors is not None:\n",
    "        keep, order = geodesic_parse_with_prior(\n",
    "            traces, priors=priors, sigma=sigma, proto_width=proto_w,\n",
    "            z=2.2, rel_floor=0.70, alpha=0.08, beta_s=0.35, q_s=2.0\n",
    "        )\n",
    "        passed = bool(keep)\n",
    "        info   = {\"keep\": keep, \"order\": order, \"sigma\": sigma, \"proto_w\": proto_w, \"mode\":\"prior\"}\n",
    "    else:\n",
    "        keep, order, dbg = geodesic_parse_report_conf(traces, sigma=sigma, proto_width=proto_w)\n",
    "        passed = False\n",
    "        if keep:\n",
    "            # area floor on the best kept channel\n",
    "            k = keep[0]; ch = int(k)\n",
    "            peak = dbg[\"channels\"][k][\"peak_idx\"]\n",
    "            if _area_ok(traces[ch], peak):\n",
    "                # absolute CFAR on residual stream (recompute residual view the same way the parser does)\n",
    "                # quick residual approx: center each channel then subtract mean across channels\n",
    "                X = np.stack(traces, 1); Xc = X - X.mean(0, keepdims=True)\n",
    "                resid = Xc[:, ch]\n",
    "                q = half_sine_proto(width=proto_w)\n",
    "                c = nxcorr(resid, q, mode=\"same\")\n",
    "                thr = null_threshold(resid, q, shifts=600, z=2.4, mode=\"perm\")\n",
    "                passed = float(c.max()) >= float(thr)\n",
    "        info = {\"keep\": keep, \"order\": order, \"sigma\": sigma, \"proto_w\": proto_w, \"mode\":\"report\"}\n",
    "\n",
    "    if mapper is not None and passed:\n",
    "        lbl = mapper.predict([\" \"])[0]  # replace with your prompt variable if available\n",
    "        if lbl not in allow:\n",
    "            return False, {**info, \"reason\":\"intent_mismatch\", \"label\": lbl}\n",
    "\n",
    "    return passed, info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "892990a2-a160-48f7-9a93-5c5e9ea99093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASS {'keep': ['1'], 'order': ['1'], 'sigma': 3, 'proto_w': 11, 'dbg': {'channels': {'0': {'peak_idx': 3, 'z_res': -1.820862128793049, 'z_raw': -1.3018366857035226, 'z_cm': -0.2763791283445771, 'score': -2.341596803074458}, '1': {'peak_idx': 5, 'z_res': 2.930356015228629, 'z_raw': 3.3201549913281116, 'z_cm': -0.2763791283445771, 'score': 4.258418011759874}, '2': {'peak_idx': 2, 'z_res': -1.93899111437996, 'z_raw': -1.9461171041916485, 'z_cm': -0.2763791283445771, 'score': -2.7174379560566195}}, 'smax': 4.258418011760874}}\n"
     ]
    }
   ],
   "source": [
    "text = \"borrow 500 USDC with ETH collateral at 70% ltv\"\n",
    "Yw = apply_warp_to_text(text)\n",
    "traces = [Yw[:,0], Yw[:,1], Yw[:,2]]\n",
    "passed, info = ngf_pass_from_traces(traces, priors=None)  # or priors=your_funnel_priors\n",
    "print(\"PASS\" if passed else \"ABSTAIN\", info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92c278b5-9ef8-4f82-afbb-c05ca13451d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABSTAIN {'keep': ['1'], 'order': ['1'], 'sigma': 3, 'proto_w': 11, 'mode': 'report'}\n"
     ]
    }
   ],
   "source": [
    "text = \"swap 10 ETH to USDC on uniswap\"\n",
    "\n",
    "text = normalize_protocols(text)\n",
    "Yw = apply_warp_to_text(text)\n",
    "\n",
    "#Yw = apply_warp_to_text(text)\n",
    "traces = [Yw[:,0], Yw[:,1], Yw[:,2]]\n",
    "passed, info = ngf_pass_strict(traces, priors=None)  # or priors=your_funnel_priors\n",
    "print(\"PASS\" if passed else \"ABSTAIN\", info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29ff06e3-8a5e-4185-bc35-307db057e82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABSTAIN {'keep': ['0', '1'], 'order': ['1', '0'], 'sigma': 3, 'proto_w': 11, 'mode': 'report'}\n"
     ]
    }
   ],
   "source": [
    "text = \"thats a wrap\"\n",
    "Yw = apply_warp_to_text(text)\n",
    "traces = [Yw[:,0], Yw[:,1], Yw[:,2]]\n",
    "passed, info = ngf_pass_strict(traces, priors=None)  # or priors=your_funnel_priors\n",
    "print(\"PASS\" if passed else \"ABSTAIN\", info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ee06fb8-297a-47bd-9897-e38b06c40fa2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'priors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m Yw   \u001b[38;5;241m=\u001b[39m apply_warp_to_text(text)            \u001b[38;5;66;03m# [T, 3]\u001b[39;00m\n\u001b[1;32m      3\u001b[0m traces \u001b[38;5;241m=\u001b[39m [Yw[:,\u001b[38;5;241m0\u001b[39m], Yw[:,\u001b[38;5;241m1\u001b[39m], Yw[:,\u001b[38;5;241m2\u001b[39m]]       \u001b[38;5;66;03m# three channels\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m priors \u001b[38;5;241m=\u001b[39m attach_projection_info(\u001b[43mpriors\u001b[49m, proj_feat)\n\u001b[1;32m      5\u001b[0m keep, order \u001b[38;5;241m=\u001b[39m geodesic_parse_with_prior(\n\u001b[1;32m      6\u001b[0m     traces, priors,\n\u001b[1;32m      7\u001b[0m     sigma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m, proto_width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m160\u001b[39m,\n\u001b[1;32m      8\u001b[0m     alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m, beta_s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m, q_s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m      9\u001b[0m     tau_rel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.60\u001b[39m, tau_abs_q\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.93\u001b[39m, null_K\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m keep, order\n",
      "\u001b[0;31mNameError\u001b[0m: name 'priors' is not defined"
     ]
    }
   ],
   "source": [
    "text = \"borrow 500 USDC with ETH collateral at 70% ltv\"\n",
    "Yw   = apply_warp_to_text(text)            # [T, 3]\n",
    "traces = [Yw[:,0], Yw[:,1], Yw[:,2]]       # three channels\n",
    "priors = attach_projection_info(priors, proj_feat)\n",
    "keep, order = geodesic_parse_with_prior(\n",
    "    traces, priors,\n",
    "    sigma=9, proto_width=160,\n",
    "    alpha=0.05, beta_s=0.25, q_s=2,\n",
    "    tau_rel=0.60, tau_abs_q=0.93, null_K=40, seed=42\n",
    ")\n",
    "keep, order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbb06cc3-b8d2-4447-9de3-5e61642034e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1'] ['1']\n",
      "{'0': {'peak_idx': 3, 'z_res': -1.820862128793049, 'z_raw': -1.3018366857035226, 'z_cm': -0.2763791283445771, 'score': -2.341596803074458}, '1': {'peak_idx': 5, 'z_res': 2.930356015228629, 'z_raw': 3.3201549913281116, 'z_cm': -0.2763791283445771, 'score': 4.258418011759874}, '2': {'peak_idx': 2, 'z_res': -1.93899111437996, 'z_raw': -1.9461171041916485, 'z_cm': -0.2763791283445771, 'score': -2.7174379560566195}}\n"
     ]
    }
   ],
   "source": [
    "text = \"borrow 500 USDC with ETH collateral at 70% ltv\"\n",
    "Yw   = apply_warp_to_text(text)            # [T, 3]\n",
    "traces = [Yw[:,0], Yw[:,1], Yw[:,2]]       # three channels\n",
    "\n",
    "T = len(traces[0])  # tokens in your PCA channel\n",
    "proto_w = max(11, min(int(0.6 * T), 61))  # 60% of T, clamped to [11, 61]\n",
    "sigma   = max(3, min(int(T / 10), 9))     # ~ T/10, clamped to [3, 9]\n",
    "\n",
    "keep, order, dbg = geodesic_parse_report_conf(traces, sigma=sigma, proto_width=proto_w)\n",
    "print(keep, order)\n",
    "print(dbg[\"channels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8176a62-c9a4-4dbd-874f-81b97953f2e4",
   "metadata": {},
   "source": [
    "### WDD Doctrine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "664f03d4-d7fd-4df3-b754-9a1f3ee34862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt                                   | prior  | keep | sigma | proto_w | which_prior\n",
      "----------------------------------------------------------------------------------------------------\n",
      "supply 7.0245 SOL to maker               | ABSTAIN |  -   |   4   |   13    | deposit(L-6)\n",
      "swap 10 ETH to USDC on uniswap           |   PASS |  2   |   4   |   13    | swap(L-4)\n",
      "swap 10 ETH to USDC on uniswa            |   PASS |  2   |   4   |   13    | swap(L-4)\n",
      "attempt a borrow with low health factor  | ABSTAIN |  -   |   -   |    -    | unknown\n",
      "that's a wrap                            | ABSTAIN |  -   |   -   |    -    | unknown\n"
     ]
    }
   ],
   "source": [
    "# === Action-specific WDD: deposit uses earlier layer & its own warp/priors ===\n",
    "import os, re, difflib, numpy as np, torch, joblib\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# ---------------- base encoders ----------------\n",
    "BASE_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "mdl = AutoModel.from_pretrained(BASE_MODEL, output_hidden_states=True).eval()\n",
    "\n",
    "def get_hidden_states(text: str, layer_offset: int) -> np.ndarray:\n",
    "    with torch.no_grad():\n",
    "        out = mdl(**tok(text, return_tensors=\"pt\"))\n",
    "    hs = out.hidden_states\n",
    "    k  = max(-(len(hs)-1), min(layer_offset, -1))\n",
    "    return hs[k].squeeze(0).float().cpu().numpy()  # [T,H]\n",
    "\n",
    "# ---------------- PCA warp H->3 ----------------\n",
    "def fit_token_warp(hiddens, d=3, whiten=True):\n",
    "    X = np.vstack(hiddens); mu = X.mean(0); Xc = X - mu\n",
    "    U,S,Vt = np.linalg.svd(Xc, full_matrices=False)\n",
    "    pcs = Vt[:d,:]; Y = Xc @ pcs.T\n",
    "    scales = Y.std(0, ddof=1) + 1e-8 if whiten else np.ones(d)\n",
    "    return {\"mean\": mu, \"pcs\": pcs, \"scales\": scales}\n",
    "\n",
    "def apply_token_warp(Z, warp):\n",
    "    Y = (Z - warp[\"mean\"]) @ warp[\"pcs\"].T\n",
    "    return Y / (warp[\"scales\"] + 1e-8)\n",
    "\n",
    "def traces_from_text(warp, text, layer_offset):\n",
    "    Z = get_hidden_states(text, layer_offset=layer_offset)\n",
    "    Yw = apply_token_warp(Z, warp)   # [T,3]\n",
    "    return [Yw[:,0], Yw[:,1], Yw[:,2]]\n",
    "\n",
    "# ---------------- NGF bits ----------------\n",
    "from ngeodesic.core.parser import moving_average, geodesic_parse_with_prior\n",
    "from ngeodesic.core.matched_filter import half_sine_proto, nxcorr\n",
    "from ngeodesic.core.funnel_profile import (\n",
    "    fit_radial_profile, analytic_core_template, blend_profiles,\n",
    "    priors_from_profile, attach_projection_info\n",
    ")\n",
    "\n",
    "def normalize_protocols(text: str) -> str:\n",
    "    vocab = [\"uniswap\",\"maker\",\"aave\",\"compound\",\"curve\",\"balancer\"]\n",
    "    toks = text.split()\n",
    "    fixed = []\n",
    "    for t in toks:\n",
    "        cand = difflib.get_close_matches(t.lower(), vocab, n=1, cutoff=0.75)\n",
    "        fixed.append(cand[0] if cand else t)\n",
    "    return \" \".join(fixed)\n",
    "\n",
    "def infer_action(text: str) -> str:\n",
    "    t=text.lower()\n",
    "    if re.search(r\"\\b(supply|deposit)\\b\", t): return \"deposit\"\n",
    "    if re.search(r\"\\b(swap|exchange|trade)\\b\", t): return \"swap\"\n",
    "    return \"unknown\"\n",
    "\n",
    "def adaptive_windows_short(T: int):\n",
    "    # slightly wider for tiny T\n",
    "    proto_w = max(13, min(int(0.7*T), 61))\n",
    "    sigma   = max(4,  min(int(T/8),  9))\n",
    "    return sigma, proto_w\n",
    "\n",
    "def parser_features(x, w):\n",
    "    pos=np.maximum(0.0,x); ma=moving_average(pos, k=w); j=int(np.argmax(ma))\n",
    "    halfw=max(1,w//2); area=float(pos[max(0,j-halfw):j+halfw+1].sum()); meanp=float(pos.mean())\n",
    "    return np.array([j/max(1,len(x)-1), area, meanp], float)\n",
    "\n",
    "def mf_peak(x, proto_w):\n",
    "    q = half_sine_proto(width=proto_w)\n",
    "    c = nxcorr(x, q, mode=\"same\")\n",
    "    return float(np.maximum(0.0, c).max())\n",
    "\n",
    "def build_priors_feature_MFpeak(warp, texts, layer_offset, proto_w=160):\n",
    "    F, Zs = [], []\n",
    "    for t in texts:\n",
    "        tr = traces_from_text(warp, t, layer_offset=layer_offset)\n",
    "        S  = [moving_average(ch, k=min(9, max(3, len(ch)//6))) for ch in tr]\n",
    "        for ch in S:\n",
    "            F.append(parser_features(ch, w=proto_w))\n",
    "            Zs.append(mf_peak(ch, proto_w))\n",
    "    F=np.asarray(F); Zs=np.asarray(Zs)\n",
    "    center = np.median(F[:,:2], axis=0)\n",
    "    R = np.linalg.norm(F[:,:2] - center[None,:], axis=1)\n",
    "    r_grid, z_data = fit_radial_profile(R, Zs, n_r=220, fit_quantile=0.65)\n",
    "    z_core  = analytic_core_template(r_grid, k=0.18, p=1.7, r0_frac=0.14)\n",
    "    z_blend = blend_profiles(z_data, z_core, blend_core=0.25)\n",
    "    pri     = priors_from_profile(r_grid, z_blend)\n",
    "    proj    = {\"mean\": np.zeros(3), \"pcs\": np.eye(3), \"scales\": np.ones(3), \"center\": center.astype(float)}\n",
    "    return attach_projection_info(pri, proj)\n",
    "\n",
    "def wdd_prior_pass(traces, priors, *, z=1.8, rel_floor=0.58, alpha=0.14, beta_s=0.50, q_s=2.0):\n",
    "    T = len(traces[0])\n",
    "    if T < 6: return False, {\"reason\":\"too_short\",\"T\":T}\n",
    "    sigma, proto_w = adaptive_windows_short(T)\n",
    "    keep, order = geodesic_parse_with_prior(\n",
    "        traces, priors=priors, sigma=sigma, proto_width=proto_w,\n",
    "        z=z, rel_floor=rel_floor, alpha=alpha, beta_s=beta_s, q_s=q_s\n",
    "    )\n",
    "    return bool(keep), {\"keep\": keep, \"order\": order, \"sigma\": sigma, \"proto_w\": proto_w, \"mode\":\"prior\"}\n",
    "\n",
    "# ---------------- Build per-action warps & priors ----------------\n",
    "os.makedirs(\".artifacts\", exist_ok=True)\n",
    "\n",
    "# SWAP: keep your current setup at layer -4\n",
    "SWAP_LAYER  = -4\n",
    "SWAP_WARP   = \".artifacts/wdd_warp_swap_L-4.joblib\"\n",
    "SWAP_PRIORS = \".artifacts/wdd_priors_swap_L-4.joblib\"\n",
    "\n",
    "# DEPOSIT: build at earlier layer -6 for stronger token dynamics on short prompts\n",
    "DEP_LAYER  = -6\n",
    "DEP_WARP   = \".artifacts/wdd_warp_deposit_L-6.joblib\"\n",
    "DEP_PRIORS = \".artifacts/wdd_priors_deposit_L-6.joblib\"\n",
    "\n",
    "# Calibration sets (expand as needed)\n",
    "deposit_cal = [\n",
    "    \"supply 7.0245 SOL to maker\",\n",
    "    \"deposit 3 WBTC into vault\",\n",
    "    \"supply 150 USDC to aave\",\n",
    "    \"deposit 2 ETH to compound\",\n",
    "    \"supply 0.5 WETH to maker\",\n",
    "    \"deposit 200 DAI into vault\",\n",
    "    \"supply 10 SOL to aave\",\n",
    "    \"deposit 25 USDC to maker\",\n",
    "    \"supply 3 ETH to maker\",\n",
    "]\n",
    "swap_cal = [\n",
    "    \"swap 10 ETH to USDC on uniswap\",\n",
    "    \"swap 2000 USDC to ETH on uniswap\",\n",
    "    \"swap 1 WBTC for WETH on curve\",\n",
    "    \"swap 50 SOL to USDC on uniswap\",\n",
    "    \"swap 0.75 ETH to DAI on balancer\",\n",
    "    \"swap 250 DAI to USDC on uniswap\",\n",
    "]\n",
    "\n",
    "# Build/load warps\n",
    "if os.path.exists(SWAP_WARP):\n",
    "    warp_swap = joblib.load(SWAP_WARP)\n",
    "else:\n",
    "    Hs = [get_hidden_states(t, layer_offset=SWAP_LAYER) for t in swap_cal]\n",
    "    warp_swap = fit_token_warp(Hs, d=3, whiten=True); joblib.dump(warp_swap, SWAP_WARP)\n",
    "\n",
    "if os.path.exists(DEP_WARP):\n",
    "    warp_dep = joblib.load(DEP_WARP)\n",
    "else:\n",
    "    Hd = [get_hidden_states(t, layer_offset=DEP_LAYER) for t in deposit_cal]\n",
    "    warp_dep = fit_token_warp(Hd, d=3, whiten=True); joblib.dump(warp_dep, DEP_WARP)\n",
    "\n",
    "# Build priors with MF-peak targets\n",
    "priors_swap = build_priors_feature_MFpeak(warp_swap, swap_cal,    layer_offset=SWAP_LAYER, proto_w=160)\n",
    "priors_dep  = build_priors_feature_MFpeak(warp_dep,  deposit_cal, layer_offset=DEP_LAYER,  proto_w=160)\n",
    "joblib.dump(priors_swap, SWAP_PRIORS); joblib.dump(priors_dep, DEP_PRIORS)\n",
    "\n",
    "# ---------------- Test set ----------------\n",
    "tests = [\n",
    "    \"supply 7.0245 SOL to maker\",\n",
    "    \"swap 10 ETH to USDC on uniswap\",\n",
    "    \"swap 10 ETH to USDC on uniswa\",          # typo\n",
    "    \"attempt a borrow with low health factor\",\n",
    "    \"that's a wrap\",\n",
    "]\n",
    "\n",
    "print(f\"{'prompt'.ljust(40)} | prior  | keep | sigma | proto_w | which_prior\")\n",
    "print(\"-\"*100)\n",
    "for raw in tests:\n",
    "    text = normalize_protocols(raw)\n",
    "    act  = infer_action(text)\n",
    "    if act == \"swap\":\n",
    "        traces = traces_from_text(warp_swap, text, layer_offset=SWAP_LAYER)\n",
    "        ok, info = wdd_prior_pass(traces, priors_swap, z=1.8, rel_floor=0.58, alpha=0.12, beta_s=0.48)\n",
    "        which = \"swap(L-4)\"\n",
    "    elif act == \"deposit\":\n",
    "        traces = traces_from_text(warp_dep, text, layer_offset=DEP_LAYER)\n",
    "        ok, info = wdd_prior_pass(traces, priors_dep,  z=1.8, rel_floor=0.58, alpha=0.16, beta_s=0.52)\n",
    "        which = \"deposit(L-6)\"\n",
    "    else:\n",
    "        ok, info, which = False, {\"keep\":[],\"sigma\":None,\"proto_w\":None}, \"unknown\"\n",
    "\n",
    "    print(f\"{raw.ljust(40)} | {('PASS' if ok else 'ABSTAIN'):>6} | {','.join(info.get('keep',[])) or '-':^4} |\"\n",
    "          f\" {info.get('sigma') if info.get('sigma') is not None else '-':^5} |\"\n",
    "          f\" {info.get('proto_w') if info.get('proto_w') is not None else '-':^7} | {which}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2fccec9-9bf6-41d1-a245-bd995c6941d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt                                     | prior  | keep | sigma | proto_w | which_prior      | note\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "supply 7.0245 SOL to maker                 |   PASS |  0   |   4   |   13    | deposit(L-6)     | \n",
      "swap 10 ETH to USDC on uniswap             |   PASS |  2   |   4   |   13    | swap(L-4)        | \n",
      "swap 10 ETH to USDC on uniswa              |   PASS |  2   |   4   |   13    | swap(L-4)        | \n",
      "attempt a borrow with low health factor    | ABSTAIN |  -   |   -   |    -    | unknown          | \n",
      "that's a wrap                              | ABSTAIN |  -   |   -   |    -    | unknown          | \n",
      "sing a swap                                | ABSTAIN |  -   |   -   |    -    | swap(L-4)        | \n",
      "trade a pop                                | ABSTAIN |  -   |   -   |    -    | swap(L-4)        | \n",
      "trade 5.6456 WETH for AAVE on sushiswap (optimism) |   PASS |  2   |   4   |   14    | swap(L-4)        | \n",
      "trade 5.9195 ETH for ARB on sushiswap (arbitrum) |   PASS |  2   |   4   |   16    | swap(L-4)        | \n",
      "market swap 4709.1849 ARB->WBTC using uniswap on ethereum |   PASS |  2   |   4   |   15    | swap(L-4)        | \n"
     ]
    }
   ],
   "source": [
    "# === Make deposits PASS: auto-layer search (-5,-7), rebuild warp+prior, gentle gates, MF fallback ===\n",
    "import os, re, difflib, numpy as np, torch, joblib\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# ---------------- base encoder ----------------\n",
    "BASE_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "tok = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "mdl = AutoModel.from_pretrained(BASE_MODEL, output_hidden_states=True).eval()\n",
    "\n",
    "def get_hidden_states(text: str, layer_offset: int) -> np.ndarray:\n",
    "    with torch.no_grad():\n",
    "        out = mdl(**tok(text, return_tensors=\"pt\"))\n",
    "    hs = out.hidden_states\n",
    "    k  = max(-(len(hs)-1), min(layer_offset, -1))\n",
    "    return hs[k].squeeze(0).float().cpu().numpy()  # [T,H]\n",
    "\n",
    "# ---------------- PCA warp H->3 ----------------\n",
    "def fit_token_warp(hiddens, d=3, whiten=True):\n",
    "    X = np.vstack(hiddens); mu = X.mean(0); Xc = X - mu\n",
    "    U,S,Vt = np.linalg.svd(Xc, full_matrices=False)\n",
    "    pcs = Vt[:d,:]; Y = Xc @ pcs.T\n",
    "    scales = Y.std(0, ddof=1) + 1e-8 if whiten else np.ones(d)\n",
    "    return {\"mean\": mu, \"pcs\": pcs, \"scales\": scales}\n",
    "\n",
    "def apply_token_warp(Z, warp):\n",
    "    Y = (Z - warp[\"mean\"]) @ warp[\"pcs\"].T\n",
    "    return Y / (warp[\"scales\"] + 1e-8)\n",
    "\n",
    "def traces_from_text(warp, text, layer_offset):\n",
    "    Z = get_hidden_states(text, layer_offset=layer_offset)\n",
    "    Yw = apply_token_warp(Z, warp)   # [T,3]\n",
    "    return [Yw[:,0], Yw[:,1], Yw[:,2]]\n",
    "\n",
    "# ---------------- NGF bits ----------------\n",
    "from ngeodesic.core.parser import moving_average, geodesic_parse_with_prior\n",
    "from ngeodesic.core.matched_filter import half_sine_proto, nxcorr\n",
    "from ngeodesic.core.funnel_profile import (\n",
    "    fit_radial_profile, analytic_core_template, blend_profiles,\n",
    "    priors_from_profile, attach_projection_info\n",
    ")\n",
    "\n",
    "def normalize_protocols(text: str) -> str:\n",
    "    vocab = [\"uniswap\",\"maker\",\"makerdao\",\"aave\",\"compound\",\"curve\",\"balancer\"]\n",
    "    toks = text.split()\n",
    "    fixed = []\n",
    "    for t in toks:\n",
    "        cand = difflib.get_close_matches(t.lower(), vocab, n=1, cutoff=0.75)\n",
    "        fixed.append(cand[0] if cand else t)\n",
    "    # unify \"maker\" → \"makerdao\" for consistency\n",
    "    txt = \" \".join(fixed)\n",
    "    txt = re.sub(r\"\\bmaker\\b\", \"makerdao\", txt, flags=re.I)\n",
    "    return txt\n",
    "\n",
    "def infer_action(text: str) -> str:\n",
    "    t=text.lower()\n",
    "    if re.search(r\"\\b(supply|deposit)\\b\", t): return \"deposit\"\n",
    "    if re.search(r\"\\b(swap|exchange|trade)\\b\", t): return \"swap\"\n",
    "    return \"unknown\"\n",
    "\n",
    "def adaptive_windows_short(T: int):\n",
    "    proto_w = max(13, min(int(0.7*T), 61))\n",
    "    sigma   = max(4,  min(int(T/8),  9))\n",
    "    return sigma, proto_w\n",
    "\n",
    "def parser_features(x, w):\n",
    "    pos=np.maximum(0.0,x); ma=moving_average(pos, k=w); j=int(np.argmax(ma))\n",
    "    halfw=max(1,w//2); area=float(pos[max(0,j-halfw):j+halfw+1].sum()); meanp=float(pos.mean())\n",
    "    return np.array([j/max(1,len(x)-1), area, meanp], float)\n",
    "\n",
    "def mf_peak(x, proto_w):\n",
    "    q = half_sine_proto(width=proto_w)\n",
    "    c = nxcorr(x, q, mode=\"same\")\n",
    "    return float(np.maximum(0.0, c).max())\n",
    "\n",
    "def build_priors_feature_MFpeak(warp, texts, layer_offset, proto_w=160):\n",
    "    F, Zs = [], []\n",
    "    for t in texts:\n",
    "        tr = traces_from_text(warp, t, layer_offset=layer_offset)\n",
    "        S  = [moving_average(ch, k=min(9, max(3, len(ch)//6))) for ch in tr]\n",
    "        for ch in S:\n",
    "            F.append(parser_features(ch, w=proto_w))\n",
    "            Zs.append(mf_peak(ch, proto_w))\n",
    "    F=np.asarray(F); Zs=np.asarray(Zs)\n",
    "    center = np.median(F[:,:2], axis=0)\n",
    "    R = np.linalg.norm(F[:,:2] - center[None,:], axis=1)\n",
    "    r_grid, z_data = fit_radial_profile(R, Zs, n_r=220, fit_quantile=0.65)\n",
    "    z_core  = analytic_core_template(r_grid, k=0.18, p=1.7, r0_frac=0.14)\n",
    "    z_blend = blend_profiles(z_data, z_core, blend_core=0.25)\n",
    "    pri     = priors_from_profile(r_grid, z_blend)\n",
    "    proj    = {\"mean\": np.zeros(3), \"pcs\": np.eye(3), \"scales\": np.ones(3), \"center\": center.astype(float)}\n",
    "    return attach_projection_info(pri, proj)\n",
    "\n",
    "def wdd_prior_pass(traces, priors, *, z=1.7, rel_floor=0.55, alpha=0.16, beta_s=0.54, q_s=2.0):\n",
    "    T = len(traces[0])\n",
    "    if T < 6: return False, {\"reason\":\"too_short\",\"T\":T}\n",
    "    sigma, proto_w = adaptive_windows_short(T)\n",
    "    keep, order = geodesic_parse_with_prior(\n",
    "        traces, priors=priors, sigma=sigma, proto_width=proto_w,\n",
    "        z=z, rel_floor=rel_floor, alpha=alpha, beta_s=beta_s, q_s=q_s\n",
    "    )\n",
    "    return bool(keep), {\"keep\": keep, \"order\": order, \"sigma\": sigma, \"proto_w\": proto_w, \"mode\":\"prior\"}\n",
    "\n",
    "# ---------------- Existing swap path (kept at L=-4) ----------------\n",
    "SWAP_LAYER = -4\n",
    "swap_cal = [\n",
    "    \"swap 10 ETH to USDC on uniswap\",\n",
    "    \"swap 2000 USDC to ETH on uniswap\",\n",
    "    \"swap 1 WBTC for WETH on curve\",\n",
    "    \"swap 50 SOL to USDC on uniswap\",\n",
    "    \"swap 0.75 ETH to DAI on balancer\",\n",
    "    \"swap 250 DAI to USDC on uniswap\",\n",
    "]\n",
    "SWAP_WARP   = \".artifacts/wdd_warp_swap_L-4.joblib\"\n",
    "SWAP_PRIORS = \".artifacts/wdd_priors_swap_L-4.joblib\"\n",
    "\n",
    "if os.path.exists(SWAP_WARP):\n",
    "    warp_swap = joblib.load(SWAP_WARP)\n",
    "else:\n",
    "    Hs = [get_hidden_states(t, layer_offset=SWAP_LAYER) for t in swap_cal]\n",
    "    warp_swap = fit_token_warp(Hs, d=3, whiten=True); joblib.dump(warp_swap, SWAP_WARP)\n",
    "\n",
    "if os.path.exists(SWAP_PRIORS):\n",
    "    priors_swap = joblib.load(SWAP_PRIORS)\n",
    "else:\n",
    "    priors_swap = build_priors_feature_MFpeak(warp_swap, swap_cal, SWAP_LAYER, proto_w=160)\n",
    "    joblib.dump(priors_swap, SWAP_PRIORS)\n",
    "\n",
    "# ---------------- Deposit path: auto-pick best layer ----------------\n",
    "deposit_cal = [\n",
    "    \"supply 7.0245 SOL to makerdao\",\n",
    "    \"deposit 3 WBTC into vault\",\n",
    "    \"supply 150 USDC to aave\",\n",
    "    \"deposit 2 ETH to compound\",\n",
    "    \"supply 0.5 WETH to makerdao\",\n",
    "    \"deposit 200 DAI into vault\",\n",
    "    \"supply 10 SOL to aave\",\n",
    "    \"deposit 25 USDC to makerdao\",\n",
    "    \"supply 3 ETH to makerdao\",\n",
    "]\n",
    "DEP_CAND_LAYERS = [-5, -6, -7]\n",
    "\n",
    "def avg_mf_on_cal(layer):\n",
    "    # build a quick warp per layer, measure mean MF peak across deposit cal\n",
    "    Hd = [get_hidden_states(t, layer_offset=layer) for t in deposit_cal]\n",
    "    w  = fit_token_warp(Hd, d=3, whiten=True)\n",
    "    peaks = []\n",
    "    for t in deposit_cal:\n",
    "        tr = traces_from_text(w, t, layer_offset=layer)\n",
    "        # mild smoothing on each channel, take max across channels\n",
    "        pks = []\n",
    "        for ch in tr:\n",
    "            T = len(ch); proto_w = max(13, min(int(0.7*T), 61))\n",
    "            pks.append(mf_peak(moving_average(ch, k=min(9, max(3, T//6))), proto_w))\n",
    "        peaks.append(max(pks))\n",
    "    return np.mean(peaks), w\n",
    "\n",
    "best_layer, best_warp, best_score = None, None, -1\n",
    "for L in DEP_CAND_LAYERS:\n",
    "    score, w = avg_mf_on_cal(L)\n",
    "    if score > best_score:\n",
    "        best_score, best_layer, best_warp = score, L, w\n",
    "\n",
    "# persist the best deposit warp + priors\n",
    "DEP_LAYER  = best_layer\n",
    "DEP_WARP   = f\".artifacts/wdd_warp_deposit_L{DEP_LAYER}.joblib\"\n",
    "DEP_PRIORS = f\".artifacts/wdd_priors_deposit_L{DEP_LAYER}.joblib\"\n",
    "joblib.dump(best_warp, DEP_WARP)\n",
    "priors_dep = build_priors_feature_MFpeak(best_warp, deposit_cal, DEP_LAYER, proto_w=160)\n",
    "joblib.dump(priors_dep, DEP_PRIORS)\n",
    "\n",
    "# ---------------- Test set (+ deposit fallback) ----------------\n",
    "def deposit_fallback_pass(traces, floor=0.18):\n",
    "    # if prior abstains but MF peak (any channel) is decent, accept\n",
    "    T = len(traces[0]); proto_w = max(13, min(int(0.7*T), 61))\n",
    "    mx = 0.0\n",
    "    for ch in traces:\n",
    "        mx = max(mx, mf_peak(moving_average(ch, k=min(9, max(3, len(ch)//6))), proto_w))\n",
    "    return mx >= floor, mx\n",
    "\n",
    "tests = [\n",
    "    \"supply 7.0245 SOL to maker\",        # normalizes to makerdao\n",
    "    \"swap 10 ETH to USDC on uniswap\",\n",
    "    \"swap 10 ETH to USDC on uniswa\",\n",
    "    \"attempt a borrow with low health factor\",\n",
    "    \"that's a wrap\",\n",
    "    \"sing a swap\",\n",
    "    \"trade a pop\",\n",
    "    \"trade 5.6456 WETH for AAVE on sushiswap (optimism)\",\n",
    "    \"trade 5.9195 ETH for ARB on sushiswap (arbitrum)\",\n",
    "    \"market swap 4709.1849 ARB->WBTC using uniswap on ethereum\",\n",
    "]\n",
    "\n",
    "print(f\"{'prompt'.ljust(42)} | prior  | keep | sigma | proto_w | which_prior      | note\")\n",
    "print(\"-\"*120)\n",
    "for raw in tests:\n",
    "    text = normalize_protocols(raw)\n",
    "    act  = infer_action(text)\n",
    "    note = \"\"  # <-- ensure defined for all branches\n",
    "\n",
    "    if act == \"swap\":\n",
    "        traces = traces_from_text(warp_swap, text, layer_offset=SWAP_LAYER)\n",
    "        ok, info = wdd_prior_pass(traces, priors_swap, z=1.7, rel_floor=0.55, alpha=0.14, beta_s=0.50)\n",
    "        which = \"swap(L-4)\"\n",
    "\n",
    "    elif act == \"deposit\":\n",
    "        traces = traces_from_text(best_warp, text, layer_offset=DEP_LAYER)\n",
    "        ok, info = wdd_prior_pass(traces, priors_dep,  z=1.7, rel_floor=0.55, alpha=0.16, beta_s=0.54)\n",
    "        which = f\"deposit(L{DEP_LAYER})\"\n",
    "        if not ok:\n",
    "            # fallback: MF floor\n",
    "            ok_fallback, mx = deposit_fallback_pass(traces, floor=0.18)\n",
    "            if ok_fallback:\n",
    "                ok = True\n",
    "                info.setdefault(\"keep\", [])\n",
    "                note = f\"fallback: MF_peak={mx:.2f}\"\n",
    "            else:\n",
    "                note = f\"mf={mx:.2f}\"\n",
    "    else:\n",
    "        ok, info, which = False, {\"keep\":[], \"sigma\":None, \"proto_w\":None}, \"unknown\"\n",
    "\n",
    "    print(f\"{raw.ljust(42)} | {('PASS' if ok else 'ABSTAIN'):>6} | {','.join(info.get('keep',[])) or '-':^4} | \"\n",
    "          f\"{info.get('sigma') if info.get('sigma') is not None else '-':^5} | \"\n",
    "          f\"{info.get('proto_w') if info.get('proto_w') is not None else '-':^7} | \"\n",
    "          f\"{which:<16} | {note}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c068b05-cd8c-4299-b7cb-c6f8079b30b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from micro_lm.verify.wdd_helpers import make_trace_encoder, build_and_save_warp, build_priors_from_texts\n",
    "import joblib\n",
    "\n",
    "enc = make_trace_encoder()\n",
    "cal_texts = [\n",
    "    # deposit\n",
    "    \"supply 7.0245 SOL to maker\",\n",
    "    \"deposit 16.104 WETH into stargate on base\",\n",
    "    \"supply 34.3849 AVAX to lido\",\n",
    "    \"fund compound with 3877.0728 ARB (optimism) — this minute\",\n",
    "    \"add liquidity: deposit 21761 USDC to sushiswap (arbitrum)\",\n",
    "    \"deposit 19057 USDT into pendle on polygon\",\n",
    "    \"add liquidity: deposit 504.9005 ARB to yearn (polygon)\",\n",
    "    \"supply 1394.564 ARB to yearn — today\",\n",
    "    \"supply 1777.8921 ARB to curve — ok with higher gas\",\n",
    "    \"fund uniswap with 33.9314 SOL (optimism)\",\n",
    "    # swap\n",
    "    \"swap 10 ETH to USDC on uniswap\",\n",
    "    \"trade 38.4142 WETH for AAVE on balancer (polygon) with slippage 1%\",\n",
    "    \"market swap 15289 USDT->OP using balancer on avalanche\",\n",
    "    \"trade 4047.6346 LINK for ETH on sushiswap (solana) with slippage 0.5% — asap\",\n",
    "    \"trade 5.6456 WETH for AAVE on sushiswap (optimism)\",\n",
    "    \"trade 5.9195 ETH for ARB on sushiswap (arbitrum)\",\n",
    "    \"market swap 4709.1849 ARB->WBTC using uniswap on ethereum\",\n",
    "    \"market swap 27.444 SOL->AAVE using uniswap on ethereum — asap\",\n",
    "    \"convert 751.3489 AAVE into ARB via curve on solana with slippage 0.2%\",\n",
    "    \"trade 14.6456 WETH for OP on sushiswap (arbitrum) — asap, high yield mode\"\n",
    "]\n",
    "\n",
    "warp = build_and_save_warp(enc, cal_texts, path=\".artifacts/wdd_token_warp.joblib\")\n",
    "priors = build_priors_from_texts(enc, warp, cal_texts)\n",
    "joblib.dump(priors, \".artifacts/wdd_priors.joblib\")\n",
    "\n",
    "# priors = build_priors_from_texts(enc, warp, cal_texts, proto_w=160)  # cal_texts include swaps + deposits\n",
    "# joblib.dump(priors, \".artifacts/wdd_priors.joblib\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
