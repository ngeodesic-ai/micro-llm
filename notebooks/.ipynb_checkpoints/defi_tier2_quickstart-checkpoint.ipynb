{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77502adf-d010-4789-9083-32e5c44b9119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd =  os.getcwd().replace(\"notebooks\",\"\")\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b670f0fa-8d84-40e6-8380-123f52d71a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoders shim ready (SBERTEncoder + SBERTFeaturizer) and sys.path configured\n"
     ]
    }
   ],
   "source": [
    "# --- Robust notebook shim for legacy joblib artifacts expecting `encoders.*` ---\n",
    "import sys, types, numpy as np\n",
    "\n",
    "# Create/replace a lightweight 'encoders' module in sys.modules\n",
    "enc_mod = types.ModuleType(\"encoders\")\n",
    "\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "except Exception as e:\n",
    "    SentenceTransformer = None\n",
    "    print(\"NOTE: sentence-transformers not available:\", e)\n",
    "\n",
    "class _SBERTBase:\n",
    "    \"\"\"\n",
    "    Compat shim implementing the sklearn Transformer API expected by saved Pipelines.\n",
    "    Handles pickles that don't call __init__ and are missing attributes.\n",
    "    Provides both class names: SBERTEncoder and SBERTFeaturizer.\n",
    "    \"\"\"\n",
    "    # NOTE: __init__ might not be called during unpickle; use _ensure_attrs() everywhere.\n",
    "    def __init__(self, model=\"sentence-transformers/all-MiniLM-L6-v2\", **kwargs):\n",
    "        self.model_name = model\n",
    "        self._enc = None\n",
    "        self._kwargs = kwargs\n",
    "\n",
    "    def _ensure_attrs(self):\n",
    "        # Add any attributes that might be missing from legacy pickles\n",
    "        if not hasattr(self, \"model_name\") or self.model_name is None:\n",
    "            self.model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "        if not hasattr(self, \"_enc\"):\n",
    "            self._enc = None\n",
    "        if not hasattr(self, \"_kwargs\"):\n",
    "            self._kwargs = {}\n",
    "\n",
    "    def _ensure_encoder(self):\n",
    "        self._ensure_attrs()\n",
    "        if self._enc is None:\n",
    "            if SentenceTransformer is None:\n",
    "                raise RuntimeError(\n",
    "                    \"sentence-transformers not installed in this kernel; \"\n",
    "                    \"pip install sentence-transformers && restart kernel\"\n",
    "                )\n",
    "            self._enc = SentenceTransformer(self.model_name)\n",
    "\n",
    "    # sklearn API\n",
    "    def fit(self, X, y=None):\n",
    "        self._ensure_attrs()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        self._ensure_encoder()\n",
    "        return np.asarray(self._enc.encode(list(X), show_progress_bar=False))\n",
    "\n",
    "    # some older code may call .encode directly; alias it\n",
    "    def encode(self, X):\n",
    "        return self.transform(X)\n",
    "\n",
    "# Expose both legacy names on the encoders module\n",
    "class SBERTEncoder(_SBERTBase): ...\n",
    "class SBERTFeaturizer(_SBERTBase): ...\n",
    "\n",
    "enc_mod.SBERTEncoder = SBERTEncoder\n",
    "enc_mod.SBERTFeaturizer = SBERTFeaturizer\n",
    "sys.modules[\"encoders\"] = enc_mod\n",
    "\n",
    "# Make sure your package code is importable too (if needed)\n",
    "import pathlib\n",
    "if str(pathlib.Path(\"src\").resolve()) not in sys.path:\n",
    "    sys.path.append(str(pathlib.Path(\"src\").resolve()))\n",
    "print(\"encoders shim ready (SBERTEncoder + SBERTFeaturizer) and sys.path configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b448ea2f-00a7-4020-9b4a-d6d35afed36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: /Users/ian_moore/repos/micro-lm/.artifacts/defi_mapper.joblib\n",
      "Pipeline(steps=[('sbertencoder', <__main__.SBERTEncoder object at 0x30a8f72e0>),\n",
      "                ('calibratedclassifiercv',\n",
      "                 CalibratedClassifierCV(cv=3,\n",
      "                                        estimator=LogisticRegression(C=8.0,\n",
      "                                                                     class_weight='balanced',\n",
      "                                                                     max_iter=2000,\n",
      "                                                                     random_state=0),\n",
      "                                        method='isotonic'))])\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "def load_mapper():\n",
    "    for name in [\".artifacts/defi_mapper.joblib\", \".artifacts/defi_mapper_embed.joblib\"]:\n",
    "        p = Path(name).resolve()\n",
    "        if p.exists():\n",
    "            print(\"Loading:\", p.as_posix())\n",
    "            return joblib.load(p.as_posix())\n",
    "    raise FileNotFoundError(\"No mapper artifact found in .artifacts/\")\n",
    "\n",
    "pipe = load_mapper()\n",
    "print(pipe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a8aefa4-cfe0-444f-bd8f-a3425490a167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[debug] mapper fallback for 'supply 7.0245 SOL to maker' -> deposit_asset\n",
      "{\n",
      "  \"verify\": {\n",
      "    \"ok\": false,\n",
      "    \"reason\": \"abstain_non_exec\"\n",
      "  },\n",
      "  \"plan\": {},\n",
      "  \"flags\": {\n",
      "    \"mapper_fallback\": true\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os, sys, warnings, importlib, __main__, json\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Path to your workspace (src + scripts)\n",
    "ROOT = os.getcwd()\n",
    "SRC = os.path.join(ROOT, \"src\")\n",
    "SCRIPTS = os.path.join(ROOT, \"scripts\")\n",
    "for p in (SRC, SCRIPTS):\n",
    "    if p not in sys.path: sys.path.insert(0, p)\n",
    "\n",
    "# Legacy pickle compat for mappers (if needed)\n",
    "def legacy_install_inline(target=\"micro_lm.domains.defi.benches.encoders\"):\n",
    "    mod = importlib.import_module(target)\n",
    "    sys.modules.setdefault(\"encoders\", mod)\n",
    "    for name in (\"SBERTEncoder\",\"SbertEncoder\",\"EmbedVectorizer\",\"SBERTVectorizer\"):\n",
    "        if hasattr(mod, name) and not hasattr(__main__, name):\n",
    "            setattr(__main__, name, getattr(mod, name))\n",
    "legacy_install_inline()\n",
    "\n",
    "# Use the harness's runner (same path the CLI uses)\n",
    "from scripts.tier2_benchmark import run_once\n",
    "\n",
    "def tier2_run_micro(domain, prompt, *, context, policy, rails=\"stage11\", T=1):\n",
    "    \"\"\"Notebook-friendly Tier-2 call that returns plan/verify/flags.\"\"\"\n",
    "    out = run_once(domain=domain, prompt=prompt, context=context, policy=policy, rails=rails, T=T)\n",
    "    # normalize to a compact dict\n",
    "    return {\n",
    "        \"plan\": out.get(\"plan\"),\n",
    "        \"verify\": out.get(\"verify\"),\n",
    "        \"flags\": out.get(\"flags\"),\n",
    "        \"raw\": out,  # keep original if you want to inspect\n",
    "    }\n",
    "\n",
    "# Example call\n",
    "policy = {\n",
    "    \"ltv_max\": 0.75, \"hf_min\": 1.0,\n",
    "    \"audit\": {\"backend\": \"wdd\", \"mode\": \"pure\", \"profile\": False, \"max_null\": 64, \"batch\": 32},\n",
    "    \"mapper\": {\"model_path\": \".artifacts/defi_mapper.joblib\", \"confidence_threshold\": 0.45},\n",
    "}\n",
    "context = {\"oracle\": {\"age_sec\": 5, \"max_age_sec\": 30}}\n",
    "\n",
    "res = tier2_run_micro(\"defi\", \"supply 7.0245 SOL to maker\", context=context, policy=policy)\n",
    "print(json.dumps({\"verify\":res[\"verify\"], \"plan\":res[\"plan\"], \"flags\":res[\"flags\"]}, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9160cd5-1021-4a0d-8723-1eeda884981a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runner file: /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/micro_lm/core/runner.py\n",
      "run_micro preview:\n",
      " def run_micro(\n",
      "    domain: str,\n",
      "    prompt: str,\n",
      "    *,\n",
      "    context: dict,\n",
      "    policy: dict,\n",
      "    rails: str,\n",
      "    T: int,\n",
      "    backend: str = \"sbert\",\n",
      ") -> dict:\n",
      "    \"\"\"\n",
      "    PUBLIC API (stable).\n",
      "    Returns a dict with: ok, label, score, reason, artifacts.\n",
      "    \"\"\"\n",
      "    # 1) Map prompt -> (label, score, aux) via selected backend\n",
      "    mapper = MapperAPI(backend=backend, domain=domain, policy=policy)\n",
      "    label, score, aux = mapper.map_prompt(prompt)\n",
      "\n",
      "    # 1b) Optional shim fallback (skip for Tier-0 wo\n",
      "keys: ['ok', 'label', 'score', 'reason', 'artifacts']\n",
      "verify: None\n",
      "plan: None\n"
     ]
    }
   ],
   "source": [
    "import os, sys, warnings, importlib, inspect\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# 1) Make sure we import from your workspace\n",
    "SRC = os.path.join(os.getcwd(), \"src\")\n",
    "if SRC not in sys.path: sys.path.insert(0, SRC)\n",
    "\n",
    "# 2) Nuke typical shim toggles (set all to \"off\"/falsey)\n",
    "for k in [\n",
    "    \"MICRO_LM_SHIM\", \"MICRO_LM_USE_SHIM\", \"MICRO_LM_STAGE4_SHIM\",\n",
    "    \"MLM_SHIM\", \"MLM_USE_SHIM\"\n",
    "]:\n",
    "    os.environ.pop(k, None)\n",
    "\n",
    "# 3) Clean import state (in case the shim was already loaded)\n",
    "for m in list(sys.modules):\n",
    "    if m.startswith(\"micro_lm.core.runner\"):\n",
    "        del sys.modules[m]\n",
    "import micro_lm.core.runner as R\n",
    "from importlib import reload\n",
    "R = reload(R)\n",
    "\n",
    "# 4) Confirm we did NOT load a shim: real rails run_micro must not return\n",
    "# only {'ok','label','score','reason','artifacts'}\n",
    "src_snippet = inspect.getsource(R.run_micro)\n",
    "print(\"runner file:\", R.__file__)\n",
    "print(\"run_micro preview:\\n\", src_snippet[:500])\n",
    "\n",
    "# crude check: reject a tiny shim that builds a dict with 'ok','label'\n",
    "if \"ok\" in src_snippet and \"label\" in src_snippet and \"plan\" not in src_snippet and \"verify\" not in src_snippet:\n",
    "    raise RuntimeError(\"Still seeing a shimmed run_micro; check your installed package vs src import.\")\n",
    "\n",
    "# 5) Call the real rails pipeline\n",
    "from micro_lm.core.runner import run_micro\n",
    "\n",
    "policy = {\n",
    "    \"ltv_max\": 0.75,\n",
    "    \"hf_min\": 1.0,\n",
    "    \"audit\": {\"backend\": \"wdd\", \"mode\": \"pure\", \"profile\": False, \"max_null\": 64, \"batch\": 32},\n",
    "    # mapper can be present; rails still decide verify/plan\n",
    "    \"mapper\": {\"model_path\": \".artifacts/defi_mapper.joblib\", \"confidence_threshold\": 0.45},\n",
    "}\n",
    "context = {\"oracle\": {\"age_sec\": 5, \"max_age_sec\": 30}}\n",
    "prompt = \"supply 7.0245 SOL to maker\"\n",
    "\n",
    "out = run_micro(domain=\"defi\", prompt=prompt, context=context, policy=policy, rails=\"stage11\", T=1)\n",
    "\n",
    "# Show what Tier-2 should expose\n",
    "print(\"keys:\", list(out.keys()))\n",
    "print(\"verify:\", out.get(\"verify\"))\n",
    "print(\"plan:\", out.get(\"plan\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb9ed05a-c659-4c44-a0e1-ebed7d624a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verify: None\n",
      "plan: None\n",
      "top1: deposit_asset flags: {'mapper_fallback': True}\n"
     ]
    }
   ],
   "source": [
    "import os, sys, warnings, joblib, numpy as np\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Ensure src/ is importable\n",
    "SRC = os.path.join(os.getcwd(), \"src\")\n",
    "if SRC not in sys.path: sys.path.insert(0, SRC)\n",
    "\n",
    "# Import Tier-2 runner\n",
    "from micro_lm.core.runner import run_micro\n",
    "\n",
    "# Tier-2 style policy = Stage-11 rails + WDD audit + mapper fallback\n",
    "POLICY = {\n",
    "    \"ltv_max\": 0.75,\n",
    "    \"hf_min\": 1.0,\n",
    "    \"audit\": {\"backend\": \"wdd\", \"mode\": \"pure\", \"profile\": False, \"max_null\": 64, \"batch\": 32},\n",
    "    \"mapper\": {\"model_path\": \".artifacts/defi_mapper.joblib\", \"confidence_threshold\": 0.45},\n",
    "}\n",
    "CONTEXT = {\"oracle\": {\"age_sec\": 5, \"max_age_sec\": 30}}\n",
    "\n",
    "# Example Tier-2 prompt\n",
    "prompt = \"supply 7.0245 SOL to maker\"\n",
    "\n",
    "# Call the real Stage-11 rails pipeline\n",
    "out = run_micro(\n",
    "    domain=\"defi\",\n",
    "    prompt=prompt,\n",
    "    context=CONTEXT,\n",
    "    policy=POLICY,\n",
    "    rails=\"stage11\",\n",
    "    T=180,\n",
    ")\n",
    "\n",
    "# If no plan was produced, do mapper fallback (like tier2_benchmark)\n",
    "def _predict_one(model, text):\n",
    "    if hasattr(model, \"predict\"): return model.predict([text])[0]\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        proba = model.predict_proba([text])[0]\n",
    "        labels = getattr(model, \"classes_\", None)\n",
    "        return labels[int(np.argmax(proba))] if labels is not None else None\n",
    "\n",
    "seq = (out.get(\"plan\") or {}).get(\"sequence\") or []\n",
    "top1 = seq[0] if seq else None\n",
    "if top1 is None and POLICY.get(\"mapper\", {}).get(\"model_path\"):\n",
    "    mapper = joblib.load(POLICY[\"mapper\"][\"model_path\"])\n",
    "    m_top1 = _predict_one(mapper, prompt)\n",
    "    if m_top1:\n",
    "        top1 = m_top1\n",
    "        out.setdefault(\"flags\", {})[\"mapper_fallback\"] = True\n",
    "\n",
    "print(\"verify:\", out.get(\"verify\"))\n",
    "print(\"plan:\", out.get(\"plan\"))\n",
    "print(\"top1:\", top1, \"flags:\", out.get(\"flags\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
