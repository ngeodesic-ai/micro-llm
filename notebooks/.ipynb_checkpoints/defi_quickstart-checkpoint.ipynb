{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87f70eb5-591f-4d74-937b-eae6e70296df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd =  os.getcwd().replace(\"notebooks\",\"\")\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5633dede-7719-41c0-bc52-0e3c83def4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoders shim ready (SBERTEncoder + SBERTFeaturizer) and sys.path configured\n"
     ]
    }
   ],
   "source": [
    "# --- Robust notebook shim for legacy joblib artifacts expecting `encoders.*` ---\n",
    "import sys, types, numpy as np\n",
    "\n",
    "# Create/replace a lightweight 'encoders' module in sys.modules\n",
    "enc_mod = types.ModuleType(\"encoders\")\n",
    "\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "except Exception as e:\n",
    "    SentenceTransformer = None\n",
    "    print(\"NOTE: sentence-transformers not available:\", e)\n",
    "\n",
    "class _SBERTBase:\n",
    "    \"\"\"\n",
    "    Compat shim implementing the sklearn Transformer API expected by saved Pipelines.\n",
    "    Handles pickles that don't call __init__ and are missing attributes.\n",
    "    Provides both class names: SBERTEncoder and SBERTFeaturizer.\n",
    "    \"\"\"\n",
    "    # NOTE: __init__ might not be called during unpickle; use _ensure_attrs() everywhere.\n",
    "    def __init__(self, model=\"sentence-transformers/all-MiniLM-L6-v2\", **kwargs):\n",
    "        self.model_name = model\n",
    "        self._enc = None\n",
    "        self._kwargs = kwargs\n",
    "\n",
    "    def _ensure_attrs(self):\n",
    "        # Add any attributes that might be missing from legacy pickles\n",
    "        if not hasattr(self, \"model_name\") or self.model_name is None:\n",
    "            self.model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "        if not hasattr(self, \"_enc\"):\n",
    "            self._enc = None\n",
    "        if not hasattr(self, \"_kwargs\"):\n",
    "            self._kwargs = {}\n",
    "\n",
    "    def _ensure_encoder(self):\n",
    "        self._ensure_attrs()\n",
    "        if self._enc is None:\n",
    "            if SentenceTransformer is None:\n",
    "                raise RuntimeError(\n",
    "                    \"sentence-transformers not installed in this kernel; \"\n",
    "                    \"pip install sentence-transformers && restart kernel\"\n",
    "                )\n",
    "            self._enc = SentenceTransformer(self.model_name)\n",
    "\n",
    "    # sklearn API\n",
    "    def fit(self, X, y=None):\n",
    "        self._ensure_attrs()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        self._ensure_encoder()\n",
    "        return np.asarray(self._enc.encode(list(X), show_progress_bar=False))\n",
    "\n",
    "    # some older code may call .encode directly; alias it\n",
    "    def encode(self, X):\n",
    "        return self.transform(X)\n",
    "\n",
    "# Expose both legacy names on the encoders module\n",
    "class SBERTEncoder(_SBERTBase): ...\n",
    "class SBERTFeaturizer(_SBERTBase): ...\n",
    "\n",
    "enc_mod.SBERTEncoder = SBERTEncoder\n",
    "enc_mod.SBERTFeaturizer = SBERTFeaturizer\n",
    "sys.modules[\"encoders\"] = enc_mod\n",
    "\n",
    "# Make sure your package code is importable too (if needed)\n",
    "import pathlib\n",
    "if str(pathlib.Path(\"src\").resolve()) not in sys.path:\n",
    "    sys.path.append(str(pathlib.Path(\"src\").resolve()))\n",
    "print(\"encoders shim ready (SBERTEncoder + SBERTFeaturizer) and sys.path configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95e6a52e-8eb9-4691-a7d6-6888989d63c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: /Users/ian_moore/repos/micro-lm/.artifacts/defi_mapper.joblib\n",
      "Pipeline(steps=[('sbertencoder', <__main__.SBERTEncoder object at 0x105215600>),\n",
      "                ('calibratedclassifiercv',\n",
      "                 CalibratedClassifierCV(cv=3,\n",
      "                                        estimator=LogisticRegression(C=8.0,\n",
      "                                                                     class_weight='balanced',\n",
      "                                                                     max_iter=2000,\n",
      "                                                                     random_state=0),\n",
      "                                        method='isotonic'))])\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "def load_mapper():\n",
    "    for name in [\".artifacts/defi_mapper.joblib\", \".artifacts/defi_mapper_embed.joblib\"]:\n",
    "        p = Path(name).resolve()\n",
    "        if p.exists():\n",
    "            print(\"Loading:\", p.as_posix())\n",
    "            return joblib.load(p.as_posix())\n",
    "    raise FileNotFoundError(\"No mapper artifact found in .artifacts/\")\n",
    "\n",
    "pipe = load_mapper()\n",
    "print(pipe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aab12dc9-af94-4e4e-9a1c-08e2a5edb29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1784: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: deposit_asset\n",
      "Top-3: [('deposit_asset', 1.0), ('borrow_asset', 0.0), ('claim_rewards', 0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1784: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "prompt = \"supply 7.0245 SOL to maker\"\n",
    "pred  = pipe.predict([prompt])[0]\n",
    "probs = pipe.predict_proba([prompt])[0]\n",
    "print(\"Predicted:\", pred)\n",
    "print(\"Top-3:\", sorted(zip(pipe.classes_, probs), key=lambda t: t[1], reverse=True)[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8686218-7736-4d18-91b4-0eb3c931c4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ok': True, 'label': 'deposit_asset', 'score': 1.0, 'reason': 'shim:accept:stage-4', 'artifacts': {'mapper': {'score': 1.0, 'reason': 'shim:mapper', 'artifacts': {'mapper': {'intent': 'deposit_asset', 'score': 1.0, 'topk': [('deposit_asset', 1.0), ('borrow_asset', 0.0), ('claim_rewards', 0.0), ('repay_asset', 0.0), ('stake_asset', 0.0), ('swap_asset', 0.0), ('unstake_asset', 0.0), ('withdraw_asset', 0.0)], 'reason': 'joblib:predict_proba', 'aux': None}, 'plan': {'steps': [PlanStep(op='parse_amount_asset_venue', args={'text': 'supply 7.0245 SOL to maker'}), PlanStep(op='call:aave.deposit', args={'source': 'account'})], 'rationale': 'Deposit intent â†’ parse then call aave.deposit'}}}, 'verify': {'ok': True, 'reason': 'shim:accept:stage-4'}, 'schema': {'v': 1, 'keys': ['mapper', 'verify']}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1784: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from micro_lm.core.runner import run_micro\n",
    "\n",
    "# Example prompt\n",
    "prompt = \"supply 7.0245 SOL to maker\"\n",
    "\n",
    "# Minimal policy & context\n",
    "policy = {\n",
    "    \"mapper\": {\n",
    "        \"model_path\": \".artifacts/defi_mapper.joblib\",\n",
    "        \"confidence_threshold\": 0.5,\n",
    "    }\n",
    "}\n",
    "context = {}\n",
    "\n",
    "# Run through micro-lm pipeline\n",
    "out = run_micro(\n",
    "    domain=\"defi\",\n",
    "    prompt=prompt,\n",
    "    context=context,\n",
    "    policy=policy,\n",
    "    rails=\"stage11\",\n",
    "    T=180,\n",
    "    backend=\"sbert\",   # or \"sbert\"\n",
    ")\n",
    "\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
