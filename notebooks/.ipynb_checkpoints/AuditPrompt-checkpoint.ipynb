{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32cb3817-9b2a-49a7-b89a-cd01f32566b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import json, csv, sys, os, time\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- sklearn bits\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# --- sentence-transformers for embeddings\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "except Exception as e:\n",
    "    SentenceTransformer = None\n",
    "    print(\"[WARN] sentence-transformers not importable right now. Install it to train/encode.\", file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d517287-0eb6-4be3-bfe2-f19b17cf653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- SBERT encoder (pipeline compatible) ----------------\n",
    "class SBERTEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Lightweight sentence-embedding transformer for sklearn pipelines.\"\"\"\n",
    "    def __init__(self, model_name=\"sentence-transformers/all-MiniLM-L6-v2\", batch_size: int = 64, normalize: bool = True):\n",
    "        self.model_name = model_name\n",
    "        self.batch_size = batch_size\n",
    "        self.normalize = normalize\n",
    "        self._model = None\n",
    "\n",
    "    def _ensure_model(self):\n",
    "        if self._model is None:\n",
    "            if SentenceTransformer is None:\n",
    "                raise RuntimeError(\"sentence-transformers is required to encode prompts.\")\n",
    "            self._model = SentenceTransformer(self.model_name)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self._ensure_model()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        self._ensure_model()\n",
    "        embs = self._model.encode(\n",
    "            list(X),\n",
    "            batch_size=self.batch_size,\n",
    "            show_progress_bar=False,\n",
    "            normalize_embeddings=self.normalize,\n",
    "        )\n",
    "        return np.asarray(embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73e27dec-fa6a-40a8-9eee-913095f402ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ Training ------------------------\n",
    "def train_mapper(\n",
    "    labels_csv: str,\n",
    "    out_path: str = \".artifacts/defi_mapper.joblib\",\n",
    "    sbert_model: str = \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    C: float = 8.0,\n",
    "    max_iter: int = 2000,\n",
    "    calibrate: bool = True,\n",
    "    calibration_method: str = \"auto\",  # 'auto' | 'isotonic' | 'sigmoid'\n",
    "    calibration_cv: int = 3,\n",
    ") -> str:\n",
    "    \"\"\"Train a SBERT + LogisticRegression pipeline, optionally calibrated, and dump to joblib.\"\"\"\n",
    "    os.makedirs(os.path.dirname(out_path) or \".\", exist_ok=True)\n",
    "\n",
    "    df = pd.read_csv(labels_csv)\n",
    "    need = {\"prompt\",\"label\"}\n",
    "    if not need.issubset(df.columns):\n",
    "        raise SystemExit(f\"[train_mapper] labels_csv must have columns {need}, got {df.columns.tolist()}\" )\n",
    "    df = df.dropna(subset=[\"prompt\",\"label\"]).copy()\n",
    "    df[\"prompt\"] = df[\"prompt\"].astype(str).str.strip()\n",
    "    df[\"label\"]  = df[\"label\"].astype(str).str.strip()\n",
    "    df = df[df[\"prompt\"].str.len() > 0]\n",
    "    if df.empty:\n",
    "        raise SystemExit(\"[train_mapper] No non-empty prompts after cleaning.\")\n",
    "\n",
    "    X = df[\"prompt\"].tolist()\n",
    "    y = df[\"label\"].tolist()\n",
    "\n",
    "    base = LogisticRegression(max_iter=max_iter, C=C, class_weight=\"balanced\", random_state=0)\n",
    "\n",
    "    model = base\n",
    "    if calibrate:\n",
    "        # pick a safe calibration automatically for tiny classes\n",
    "        from collections import Counter\n",
    "        cnt = Counter(y); m = min(cnt.values())\n",
    "        method = calibration_method; cv = calibration_cv\n",
    "        if method == \"auto\":\n",
    "            if m >= max(3, cv):\n",
    "                method, cv = \"isotonic\", max(3, cv)\n",
    "            elif m >= 2:\n",
    "                method, cv = \"sigmoid\", max(2, min(m, cv))\n",
    "            else:\n",
    "                print(\"[train_mapper] Not enough per-class samples for calibration; skipping.\", file=sys.stderr)\n",
    "                method = None\n",
    "        if method in (\"isotonic\",\"sigmoid\"):\n",
    "            try:\n",
    "                model = CalibratedClassifierCV(estimator=base, method=method, cv=cv)  # sklearn>=1.3\n",
    "            except TypeError:\n",
    "                model = CalibratedClassifierCV(base_estimator=base, method=method, cv=cv)  # older sklearn\n",
    "\n",
    "    pipe = make_pipeline(SBERTEncoder(sbert_model), model)\n",
    "    pipe.fit(X, y)\n",
    "    joblib.dump(pipe, out_path)\n",
    "    print(f\"[train_mapper] wrote: {out_path}  (n={len(X)})\")\n",
    "    return out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65f58935-1dc7-41b3-9dab-1bd4e9c3338a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, csv, json, os, sys, time\n",
    "def get_args():\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"--backend\",       default=\"wordmap\", help=\"wordmap|sbert\")\n",
    "    ap.add_argument(\"--model_path\",    default=\".artifacts/defi_mapper.joblib\")\n",
    "    ap.add_argument(\"--prompts_jsonl\", default=\"tests/fixtures/defi/defi_mapper_5k_prompts.json\")\n",
    "    ap.add_argument(\"--labels_csv_pred\", default=\"tests/fixtures/defi/defi_mapper_labeled_5k.csv\")\n",
    "    ap.add_argument(\"--train_labels_csv\", default=\"tests/fixtures/defi/defi_mapper_labeled_large.csv\")\n",
    "    ap.add_argument(\"--thresholds\",    default=\"0.5,0.55,0.6,0.65,0.7\")\n",
    "    ap.add_argument(\"--max_iter\",    default=\"2000\")\n",
    "    ap.add_argument(\"--C\",    default=\"8\")\n",
    "    ap.add_argument(\"--calibrate\",    default=\"True\")\n",
    "    ap.add_argument(\"--calibration_method\", choices=[\"auto\",\"isotonic\",\"sigmoid\"], default=\"auto\")\n",
    "    ap.add_argument(\"--calibration_cv\", type=int, default=3)\n",
    "    ap.add_argument(\"--sbert_model\", default=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    ap.add_argument(\"--threshold\", type=float, default=0.6)\n",
    "    ap.add_argument(\"--out_path\", default=\"defi_mapper_embed.joblib\")\n",
    "    ap.add_argument(\"--out_dir\",       default=\"\")\n",
    "    ap.add_argument(\"--out_rows_csv\", default=\".artifacts/m8_rows_simple.csv\")\n",
    "    ap.add_argument(\"--min_overall_acc\", default=None)\n",
    "    \n",
    "    notebook_args = [\n",
    "        \"--backend\", \"sbert\",\n",
    "        \"--model_path\", \".artifacts/defi_mapper.joblib\",\n",
    "        \"--prompts_jsonl\", \"tests/fixtures/defi/defi_mapper_5k_prompts.jsonl\",\n",
    "        \"--labels_csv_pred\",    \"tests/fixtures/defi/defi_mapper_labeled_5k.csv\",\n",
    "        \"--train_labels_csv\", \"tests/fixtures/defi/defi_mapper_labeled_large.csv\",\n",
    "        \"--thresholds\", \"0.5,0.55,0.6,0.65,.7\",\n",
    "        \"--max_iter\", \"2000\",\n",
    "        \"--C\", \"8\",\n",
    "        \"--calibrate\", \"True\",\n",
    "        \"--calibration_method\", \"auto\",\n",
    "        \"--calibration_cv\", \"3\",\n",
    "        \"--threshold\", \"0.5\",\n",
    "        \"--min_overall_acc\", \"0.75\",\n",
    "        \"--sbert_model\", \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        \"--out_path\", \"defi_mapper_embed.joblib\",\n",
    "        \"--out_rows_csv\", \".artifacts/m8_rows_simple.csv\",\n",
    "        \"--out_dir\", \".artifacts/defi/mapper_bench\",\n",
    "    ]\n",
    "    \n",
    "    return ap.parse_args(notebook_args)\n",
    "    \n",
    "# ------------------------ CLI (optional) ------------------------\n",
    "def _as_bool(x: str) -> bool:\n",
    "    return str(x).strip().lower() in {\"1\",\"true\",\"t\",\"yes\",\"y\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e49c75b-5518-415a-a789-e521d9bf260f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1784: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train_mapper] wrote: defi_mapper_embed.joblib  (n=1000)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cwd =  os.getcwd().replace(\"/notebooks\",\"\")\n",
    "os.chdir(cwd)\n",
    "\n",
    "args = get_args()\n",
    "\n",
    "model_path = train_mapper(\n",
    "        labels_csv=args.train_labels_csv,\n",
    "        out_path=args.out_path,\n",
    "        sbert_model=args.sbert_model,\n",
    "        C=float(args.C),\n",
    "        max_iter=int(args.max_iter),\n",
    "        calibrate=_as_bool(args.calibrate),\n",
    "        calibration_method=args.calibration_method,\n",
    "        calibration_cv=args.calibration_cv\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455b3bf9-4620-4b8b-a3c3-82d90a5467f3",
   "metadata": {},
   "source": [
    "## ChatGPT Fix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb91775f-6649-4cb8-8303-dc409dedcce1",
   "metadata": {},
   "source": [
    "### 0) seed terms + encoder + prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adce8922-bff2-455d-bea2-6433be717e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 0: seed term bank (tight, unambiguous) =====\n",
    "TERM_BANK = {\n",
    "    \"deposit_asset\":  [\"deposit\", \"supply\", \"provide\"],\n",
    "    \"withdraw_asset\": [\"withdraw\", \"redeem\", \"unstow\"],\n",
    "    \"swap_asset\":     [\"swap\", \"convert\", \"trade\", \"exchange\"],\n",
    "    \"borrow_asset\":   [\"borrow\", \"draw\"],\n",
    "    \"repay_asset\":    [\"repay\", \"pay back\"],\n",
    "    \"stake_asset\":    [\"stake\", \"lock\", \"bond\"],\n",
    "    \"unstake_asset\":  [\"unstake\", \"unlock\", \"unbond\"],\n",
    "    \"claim_rewards\":  [\"claim\", \"harvest\", \"collect rewards\"],\n",
    "}\n",
    "PRIMS = list(TERM_BANK.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6951bb89-ff86-426c-a1e4-1d6c9c86dc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 1: SBERT encoder wrapper =====\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "class Emb:\n",
    "    def __init__(self, model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "        self._m = SentenceTransformer(model_name)\n",
    "    def encode(self, texts, normalize_embeddings=True, show_progress_bar=False):\n",
    "        return self._m.encode(\n",
    "            texts, normalize_embeddings=normalize_embeddings,\n",
    "            show_progress_bar=show_progress_bar\n",
    "        )\n",
    "    def encode_one(self, text, normalize_embeddings=True):\n",
    "        return self.encode([text], normalize_embeddings=normalize_embeddings)[0]\n",
    "\n",
    "emb = Emb()  # or Emb(\"sentence-transformers/all-mpnet-base-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8788417d-4e80-461d-9ef1-e4f7dc57dff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1784: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 2: build primitive -> prototype vector (centroid over seed terms) =====\n",
    "def build_prototypes(term_bank: dict[str, list[str]], emb: Emb) -> dict[str, np.ndarray]:\n",
    "    protos = {}\n",
    "    for prim, terms in term_bank.items():\n",
    "        V = np.asarray(emb.encode(terms, normalize_embeddings=True))\n",
    "        protos[prim] = V.mean(axis=0)\n",
    "    return protos\n",
    "\n",
    "prototypes = build_prototypes(TERM_BANK, emb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4646ec3d-1e5d-498a-a1fd-c469c20dd60c",
   "metadata": {},
   "source": [
    "## 1) spans_from_prompt (your style, dict-only return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dee35d33-efe3-4af1-884b-b2aacb07f3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 3: spans_from_prompt (dict-only return) =====\n",
    "import re\n",
    "\n",
    "_WORD = re.compile(r\"[a-z0-9]+(?:'[a-z0-9]+)?\")\n",
    "\n",
    "def _norm_tokens(txt: str) -> list[str]:\n",
    "    txt = txt.lower()\n",
    "    return _WORD.findall(txt)\n",
    "\n",
    "def _cosine(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    da = float(np.linalg.norm(a) + 1e-9)\n",
    "    db = float(np.linalg.norm(b) + 1e-9)\n",
    "    return float(np.dot(a, b) / (da * db))\n",
    "\n",
    "def spans_from_prompt(prompt: str,\n",
    "                      prototypes: dict[str, np.ndarray],\n",
    "                      emb: Emb,\n",
    "                      tau_span: float = 0.55,\n",
    "                      n_max: int = 5,\n",
    "                      topk_per_prim: int = 3):\n",
    "    \"\"\"\n",
    "    Returns: dict primitive -> [ {primitive, term, score, t_center, start, len}, ... ] (top-k per primitive)\n",
    "    \"\"\"\n",
    "    toks = _norm_tokens(prompt)\n",
    "    if not toks:\n",
    "        return {}\n",
    "\n",
    "    grams, meta = [], []   # meta holds (start, n, t_center)\n",
    "    for n in range(1, min(n_max, len(toks)) + 1):\n",
    "        for i in range(0, len(toks) - n + 1):\n",
    "            s = \" \".join(toks[i:i+n])\n",
    "            t_center = (i + n/2.0) / max(1.0, len(toks))\n",
    "            grams.append(s)\n",
    "            meta.append((i, n, t_center))\n",
    "\n",
    "    V = emb.encode(grams, normalize_embeddings=True, show_progress_bar=False)  # [M, D]\n",
    "\n",
    "    by_prim: dict[str, list[dict]] = {k: [] for k in prototypes.keys()}\n",
    "    for m, (i, n, t_center) in enumerate(meta):\n",
    "        v = V[m]\n",
    "        for prim, proto in prototypes.items():\n",
    "            sc = max(0.0, _cosine(v, proto))\n",
    "            if sc >= tau_span:\n",
    "                by_prim[prim].append({\n",
    "                    \"primitive\": prim,\n",
    "                    \"term\": grams[m],\n",
    "                    \"score\": round(sc, 4),\n",
    "                    \"t_center\": round(t_center, 4),\n",
    "                    \"start\": i,\n",
    "                    \"len\": n,\n",
    "                })\n",
    "\n",
    "    # keep top-k per primitive by score\n",
    "    for prim in list(by_prim.keys()):\n",
    "        arr = sorted(by_prim[prim], key=lambda x: x[\"score\"], reverse=True)[:topk_per_prim]\n",
    "        if arr:\n",
    "            by_prim[prim] = arr\n",
    "        else:\n",
    "            # drop empty lists to make downstream checks easy\n",
    "            by_prim.pop(prim, None)\n",
    "\n",
    "    return by_prim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13a5b91-bb4e-4e7c-8371-79ae06e102bd",
   "metadata": {},
   "source": [
    "### 2) audit wrapper (robust to dict-only or (dict, meta) variants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74b24fb8-903b-4b6d-a08f-372cba3ec145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 4: audit_prompt_with_spans (robust wrapper) =====\n",
    "def audit_prompt_with_spans(prompt: str,\n",
    "                            prototypes: dict[str, np.ndarray],\n",
    "                            emb: Emb,\n",
    "                            tau_span: float = 0.55,\n",
    "                            rel_margin: float = 0.06):\n",
    "    \"\"\"\n",
    "    Uses spans_from_prompt to produce:\n",
    "      - best_primitive: lexical 'winner' (requires tau + small relative margin)\n",
    "      - scores: top-score per primitive (0 if none)\n",
    "      - spans: raw span map from spans_from_prompt\n",
    "      - rel_margin: best - second best score\n",
    "    Works whether spans_from_prompt returns dict or (dict, meta).\n",
    "    \"\"\"\n",
    "    out = spans_from_prompt(prompt, prototypes, emb, tau_span=tau_span)\n",
    "    if isinstance(out, tuple):\n",
    "        span_map, meta = out\n",
    "    else:\n",
    "        span_map, meta = out, {}\n",
    "\n",
    "    # top score per primitive (ensure we cover all prototypes, even if absent in span_map)\n",
    "    scores = {}\n",
    "    for prim in prototypes.keys():\n",
    "        lst = span_map.get(prim, [])\n",
    "        scores[prim] = (lst[0][\"score\"] if lst else 0.0)\n",
    "\n",
    "    ordered = sorted(scores.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    best_prim, best_sc = ordered[0]\n",
    "    second_sc = ordered[1][1] if len(ordered) > 1 else 0.0\n",
    "    winner = best_prim if (best_sc >= tau_span and (best_sc - second_sc) >= rel_margin) else None\n",
    "\n",
    "    return {\n",
    "        \"best_primitive\": winner,\n",
    "        \"scores\": scores,\n",
    "        \"spans\": span_map,\n",
    "        \"rel_margin\": best_sc - second_sc,\n",
    "        \"meta\": meta,\n",
    "        \"params\": {\"tau_span\": tau_span, \"rel_margin\": rel_margin},\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af4cfa2-7989-47bc-b813-e575e9e0fa73",
   "metadata": {},
   "source": [
    "### 3) opposite-primitive veto (kills tautologies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72750aeb-0826-4562-9da4-582288c4e9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 5: opposite/veto helpers =====\n",
    "OPPOSITE = {\n",
    "    \"deposit_asset\": \"withdraw_asset\",\n",
    "    \"withdraw_asset\": \"deposit_asset\",\n",
    "    \"stake_asset\": \"unstake_asset\",\n",
    "    \"unstake_asset\": \"stake_asset\",\n",
    "    \"borrow_asset\": \"repay_asset\",\n",
    "    \"repay_asset\": \"borrow_asset\",\n",
    "    # claim_rewards has no strict opposite in this simple map\n",
    "}\n",
    "\n",
    "def should_veto(mapper_top1: str | None, audit_best: str | None) -> bool:\n",
    "    if not mapper_top1 or not audit_best:\n",
    "        return False\n",
    "    return OPPOSITE.get(mapper_top1) == audit_best\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2bbe63-3d7c-4767-80e6-9f13cbf94ed2",
   "metadata": {},
   "source": [
    "### 4) fuse with mapper (single call to get final decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04fee6cb-3400-4d28-9f9d-1219485c2366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 6: fuse_decision (mapper + spans audit) =====\n",
    "import joblib\n",
    "\n",
    "def load_mapper(path=\".artifacts/defi_mapper.joblib\"):\n",
    "    return joblib.load(path)\n",
    "\n",
    "def mapper_top1_label(mapper, prompt: str):\n",
    "    # generic scikit-like pipeline\n",
    "    if hasattr(mapper, \"predict_proba\"):\n",
    "        probs = mapper.predict_proba([prompt])[0]\n",
    "        classes = list(getattr(mapper, \"classes_\", PRIMS))\n",
    "        top_idx = int(np.argmax(probs))\n",
    "        return classes[top_idx], float(probs[top_idx])\n",
    "    else:\n",
    "        lab = mapper.predict([prompt])[0]\n",
    "        return str(lab), 1.0\n",
    "\n",
    "def fuse_decision(prompt: str,\n",
    "                  mapper,\n",
    "                  prototypes: dict[str, np.ndarray],\n",
    "                  emb: Emb,\n",
    "                  conf_thr: float = 0.70,\n",
    "                  tau_span: float = 0.55,\n",
    "                  rel_margin: float = 0.06):\n",
    "    m_top, m_conf = mapper_top1_label(mapper, prompt)\n",
    "    fired = bool(m_conf >= conf_thr)\n",
    "\n",
    "    audit = audit_prompt_with_spans(prompt, prototypes, emb, tau_span=tau_span, rel_margin=rel_margin)\n",
    "    a_best = audit[\"best_primitive\"]\n",
    "\n",
    "    if not fired:\n",
    "        return {\n",
    "            \"prompt\": prompt,\n",
    "            \"decision\": \"abstain_non_exec\",\n",
    "            \"reason\": \"low_conf_mapper\",\n",
    "            \"mapper\": {\"top\": m_top, \"conf\": m_conf},\n",
    "            \"audit\": audit,\n",
    "        }\n",
    "\n",
    "    if should_veto(m_top, a_best):\n",
    "        return {\n",
    "            \"prompt\": prompt,\n",
    "            \"decision\": \"reject\",\n",
    "            \"reason\": f\"tautology_veto:{m_top}_vs_{a_best}\",\n",
    "            \"mapper\": {\"top\": m_top, \"conf\": m_conf},\n",
    "            \"audit\": audit,\n",
    "        }\n",
    "\n",
    "    # optional: require lexical alignment when audit is strong\n",
    "    if a_best and a_best != m_top:\n",
    "        return {\n",
    "            \"prompt\": prompt,\n",
    "            \"decision\": \"reject\",\n",
    "            \"reason\": f\"audit_mismatch:{m_top}_vs_{a_best}\",\n",
    "            \"mapper\": {\"top\": m_top, \"conf\": m_conf},\n",
    "            \"audit\": audit,\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"prompt\": prompt,\n",
    "        \"decision\": \"approve\",\n",
    "        \"mapper\": {\"top\": m_top, \"conf\": m_conf},\n",
    "        \"audit\": audit,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15aa143-bb27-4f58-a9ed-51ed06f7f839",
   "metadata": {},
   "source": [
    "### 5) quick smoke (copy/paste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11b55561-9f6a-4415-98d4-73e21c7a5c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1784: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1784: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1784: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "approve — deposit 10 ETH into aave\n",
      "approve — withdraw 5 ETH\n",
      "approve — swap 2 ETH for USDC on uniswap — minimize gas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1784: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1784: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1784: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1784: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1784: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstain_non_exec — check balance\n",
      "  reason: low_conf_mapper\n",
      "approve — repay 300 USDC to aave\n",
      "approve — unstake 1000 USDC from rocket pool\n",
      "abstain_non_exec — sing me a lullaby\n",
      "  reason: low_conf_mapper\n",
      "reject — convert centimeters to inches\n",
      "  reason: audit_mismatch:withdraw_asset_vs_swap_asset\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 7: quick smoke =====\n",
    "PRIMS = list(prototypes.keys())\n",
    "mapper = joblib.load(model_path)\n",
    "tests = [\n",
    "    \"deposit 10 ETH into aave\",\n",
    "    \"withdraw 5 ETH\",\n",
    "    \"swap 2 ETH for USDC on uniswap — minimize gas\",\n",
    "    \"check balance\",\n",
    "    \"repay 300 USDC to aave\",\n",
    "    \"unstake 1000 USDC from rocket pool\",\n",
    "    \"sing me a lullaby\",\n",
    "    \"convert centimeters to inches\"\n",
    "]\n",
    "for p in tests:\n",
    "    out = fuse_decision(p, mapper, prototypes, emb, conf_thr=0.70, tau_span=0.55, rel_margin=0.06)\n",
    "    print(out[\"decision\"], \"—\", p)\n",
    "    if out[\"decision\"] != \"approve\":\n",
    "        print(\"  reason:\", out.get(\"reason\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
