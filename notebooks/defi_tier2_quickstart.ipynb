{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77502adf-d010-4789-9083-32e5c44b9119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd =  os.getcwd().replace(\"notebooks\",\"\")\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b670f0fa-8d84-40e6-8380-123f52d71a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoders shim ready (SBERTEncoder + SBERTFeaturizer) and sys.path configured\n"
     ]
    }
   ],
   "source": [
    "# --- Robust notebook shim for legacy joblib artifacts expecting `encoders.*` ---\n",
    "import sys, types, numpy as np\n",
    "\n",
    "# Create/replace a lightweight 'encoders' module in sys.modules\n",
    "enc_mod = types.ModuleType(\"encoders\")\n",
    "\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "except Exception as e:\n",
    "    SentenceTransformer = None\n",
    "    print(\"NOTE: sentence-transformers not available:\", e)\n",
    "\n",
    "class _SBERTBase:\n",
    "    \"\"\"\n",
    "    Compat shim implementing the sklearn Transformer API expected by saved Pipelines.\n",
    "    Handles pickles that don't call __init__ and are missing attributes.\n",
    "    Provides both class names: SBERTEncoder and SBERTFeaturizer.\n",
    "    \"\"\"\n",
    "    # NOTE: __init__ might not be called during unpickle; use _ensure_attrs() everywhere.\n",
    "    def __init__(self, model=\"sentence-transformers/all-MiniLM-L6-v2\", **kwargs):\n",
    "        self.model_name = model\n",
    "        self._enc = None\n",
    "        self._kwargs = kwargs\n",
    "\n",
    "    def _ensure_attrs(self):\n",
    "        # Add any attributes that might be missing from legacy pickles\n",
    "        if not hasattr(self, \"model_name\") or self.model_name is None:\n",
    "            self.model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "        if not hasattr(self, \"_enc\"):\n",
    "            self._enc = None\n",
    "        if not hasattr(self, \"_kwargs\"):\n",
    "            self._kwargs = {}\n",
    "\n",
    "    def _ensure_encoder(self):\n",
    "        self._ensure_attrs()\n",
    "        if self._enc is None:\n",
    "            if SentenceTransformer is None:\n",
    "                raise RuntimeError(\n",
    "                    \"sentence-transformers not installed in this kernel; \"\n",
    "                    \"pip install sentence-transformers && restart kernel\"\n",
    "                )\n",
    "            self._enc = SentenceTransformer(self.model_name)\n",
    "\n",
    "    # sklearn API\n",
    "    def fit(self, X, y=None):\n",
    "        self._ensure_attrs()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        self._ensure_encoder()\n",
    "        return np.asarray(self._enc.encode(list(X), show_progress_bar=False))\n",
    "\n",
    "    # some older code may call .encode directly; alias it\n",
    "    def encode(self, X):\n",
    "        return self.transform(X)\n",
    "\n",
    "# Expose both legacy names on the encoders module\n",
    "class SBERTEncoder(_SBERTBase): ...\n",
    "class SBERTFeaturizer(_SBERTBase): ...\n",
    "\n",
    "enc_mod.SBERTEncoder = SBERTEncoder\n",
    "enc_mod.SBERTFeaturizer = SBERTFeaturizer\n",
    "sys.modules[\"encoders\"] = enc_mod\n",
    "\n",
    "# Make sure your package code is importable too (if needed)\n",
    "import pathlib\n",
    "if str(pathlib.Path(\"src\").resolve()) not in sys.path:\n",
    "    sys.path.append(str(pathlib.Path(\"src\").resolve()))\n",
    "print(\"encoders shim ready (SBERTEncoder + SBERTFeaturizer) and sys.path configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b448ea2f-00a7-4020-9b4a-d6d35afed36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: /Users/ian_moore/repos/micro-lm/.artifacts/defi_mapper.joblib\n",
      "Pipeline(steps=[('sbertencoder', <__main__.SBERTEncoder object at 0x3090ff340>),\n",
      "                ('calibratedclassifiercv',\n",
      "                 CalibratedClassifierCV(cv=3,\n",
      "                                        estimator=LogisticRegression(C=8.0,\n",
      "                                                                     class_weight='balanced',\n",
      "                                                                     max_iter=2000,\n",
      "                                                                     random_state=0),\n",
      "                                        method='isotonic'))])\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "def load_mapper():\n",
    "    for name in [\".artifacts/defi_mapper.joblib\", \".artifacts/defi_mapper_embed.joblib\"]:\n",
    "        p = Path(name).resolve()\n",
    "        if p.exists():\n",
    "            print(\"Loading:\", p.as_posix())\n",
    "            return joblib.load(p.as_posix())\n",
    "    raise FileNotFoundError(\"No mapper artifact found in .artifacts/\")\n",
    "\n",
    "pipe = load_mapper()\n",
    "print(pipe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a8aefa4-cfe0-444f-bd8f-a3425490a167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[debug] mapper fallback for 'supply 7.0245 SOL to maker' -> deposit_asset\n",
      "{\n",
      "  \"verify\": {\n",
      "    \"ok\": false,\n",
      "    \"reason\": \"abstain_non_exec\"\n",
      "  },\n",
      "  \"plan\": {},\n",
      "  \"flags\": {\n",
      "    \"mapper_fallback\": true\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os, sys, warnings, importlib, __main__, json\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Path to your workspace (src + scripts)\n",
    "ROOT = os.getcwd()\n",
    "SRC = os.path.join(ROOT, \"src\")\n",
    "SCRIPTS = os.path.join(ROOT, \"scripts\")\n",
    "for p in (SRC, SCRIPTS):\n",
    "    if p not in sys.path: sys.path.insert(0, p)\n",
    "\n",
    "# Legacy pickle compat for mappers (if needed)\n",
    "def legacy_install_inline(target=\"micro_lm.domains.defi.benches.encoders\"):\n",
    "    mod = importlib.import_module(target)\n",
    "    sys.modules.setdefault(\"encoders\", mod)\n",
    "    for name in (\"SBERTEncoder\",\"SbertEncoder\",\"EmbedVectorizer\",\"SBERTVectorizer\"):\n",
    "        if hasattr(mod, name) and not hasattr(__main__, name):\n",
    "            setattr(__main__, name, getattr(mod, name))\n",
    "legacy_install_inline()\n",
    "\n",
    "# Use the harness's runner (same path the CLI uses)\n",
    "from scripts.tier2_benchmark import run_once\n",
    "\n",
    "def tier2_run_micro(domain, prompt, *, context, policy, rails=\"stage11\", T=1):\n",
    "    \"\"\"Notebook-friendly Tier-2 call that returns plan/verify/flags.\"\"\"\n",
    "    out = run_once(domain=domain, prompt=prompt, context=context, policy=policy, rails=rails, T=T)\n",
    "    # normalize to a compact dict\n",
    "    return {\n",
    "        \"plan\": out.get(\"plan\"),\n",
    "        \"verify\": out.get(\"verify\"),\n",
    "        \"flags\": out.get(\"flags\"),\n",
    "        \"raw\": out,  # keep original if you want to inspect\n",
    "    }\n",
    "\n",
    "# Example call\n",
    "policy = {\n",
    "    \"ltv_max\": 0.75, \"hf_min\": 1.0,\n",
    "    \"audit\": {\"backend\": \"wdd\", \"mode\": \"pure\", \"profile\": False, \"max_null\": 64, \"batch\": 32},\n",
    "    \"mapper\": {\"model_path\": \".artifacts/defi_mapper.joblib\", \"confidence_threshold\": 0.45},\n",
    "}\n",
    "context = {\"oracle\": {\"age_sec\": 5, \"max_age_sec\": 30}}\n",
    "\n",
    "res = tier2_run_micro(\"defi\", \"supply 7.0245 SOL to maker\", context=context, policy=policy)\n",
    "print(json.dumps({\"verify\":res[\"verify\"], \"plan\":res[\"plan\"], \"flags\":res[\"flags\"]}, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dd9594b-36da-4472-84a5-ce95784f40a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-time in your environment (outside the notebook):\n",
    "# pip uninstall -y micro-lm\n",
    "# pip install -e .   # from your repo root\n",
    "\n",
    "# then in the notebook, before importing:\n",
    "import os, sys\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), \"src\"))\n",
    "for m in list(sys.modules):\n",
    "    if m == \"micro_lm\" or m.startswith(\"micro_lm.\"):\n",
    "        del sys.modules[m]\n",
    "from micro_lm.core.runner import run_micro  # now the real rails-backed version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9160cd5-1021-4a0d-8723-1eeda884981a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[debug] mapper fallback for 'deposit 10 ETH into aave' -> deposit_asset\n",
      "\n",
      "=== 'deposit 10 ETH into aave' ===\n",
      "verify: {'ok': False, 'reason': 'abstain_non_exec'}\n",
      "plan:   {}\n",
      "flags:  {'mapper_fallback': True}\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "expected an executable plan",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 68\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# 1) Supported exec: should now produce a plan and verify.ok=True\u001b[39;00m\n\u001b[1;32m     67\u001b[0m out1 \u001b[38;5;241m=\u001b[39m call(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeposit 10 ETH into aave\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (out1\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplan\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msequence\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected an executable plan\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (out1\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverify\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mok\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected verify.ok=True for a safe deposit\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# 2) Your earlier SOL/Maker example will still abstain unless you register them:\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: expected an executable plan"
     ]
    }
   ],
   "source": [
    "# --- Tier-2 rails in a notebook (DeFi, end-to-end, no shim) ---\n",
    "import os, sys, warnings, importlib, __main__, json\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "ROOT = os.getcwd()\n",
    "SRC = os.path.join(ROOT, \"src\")\n",
    "SCRIPTS = os.path.join(ROOT, \"scripts\")\n",
    "for p in (SRC, SCRIPTS):\n",
    "    if p not in sys.path: sys.path.insert(0, p)\n",
    "\n",
    "# Purge any site-packages micro_lm so we import from src/\n",
    "for m in list(sys.modules):\n",
    "    if m == \"micro_lm\" or m.startswith(\"micro_lm.\"):\n",
    "        del sys.modules[m]\n",
    "\n",
    "# Legacy pickle compat (old joblib references like 'encoders' / __main__.SBERTEncoder)\n",
    "def _legacy_install_inline(target=\"micro_lm.domains.defi.benches.encoders\"):\n",
    "    mod = importlib.import_module(target)\n",
    "    sys.modules.setdefault(\"encoders\", mod)\n",
    "    for name in (\"SBERTEncoder\",\"SbertEncoder\",\"EmbedVectorizer\",\"SBERTVectorizer\"):\n",
    "        if hasattr(mod, name) and not hasattr(__main__, name):\n",
    "            setattr(__main__, name, getattr(mod, name))\n",
    "_legacy_install_inline()\n",
    "\n",
    "# Use the exact rails-backed helper the CLI uses\n",
    "from scripts.tier2_benchmark import run_once\n",
    "\n",
    "# Tier-2 policy: rails + WDD audit; mapper only for scoring if rails abstain\n",
    "POLICY = {\n",
    "    \"ltv_max\": 0.75,\n",
    "    \"hf_min\": 1.0,\n",
    "    \"audit\": {\"backend\": \"wdd\", \"mode\": \"pure\", \"profile\": True, \"max_null\": 64, \"batch\": 32},\n",
    "    \"mapper\": {\"model_path\": \".artifacts/defi_mapper.joblib\", \"confidence_threshold\": 0.45},\n",
    "}\n",
    "\n",
    "# Minimal but sufficient domain context (register ETH + Aave)\n",
    "CONTEXT = {\n",
    "    \"oracle\": {\"age_sec\": 5, \"max_age_sec\": 30},\n",
    "    \"defi\": {\n",
    "        \"assets\": {\n",
    "            # add more if needed later (USDC, WETH, etc.)\n",
    "            \"ETH\": {\"symbol\": \"ETH\", \"decimals\": 18, \"chain\": \"ethereum\"},\n",
    "        },\n",
    "        \"venues\": {\n",
    "            # name must match what your rails expect (often \"aave\" or \"aave_v3\")\n",
    "            \"aave\": {\"type\": \"lending\", \"version\": \"v3\", \"chain\": \"ethereum\"},\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "def call(prompt, domain=\"defi\", policy=POLICY, context=CONTEXT, rails=\"stage11\", T=1, show_trace_lines=14):\n",
    "    out = run_once(domain=domain, prompt=prompt, context=context, policy=policy, rails=rails, T=T)\n",
    "    print(f\"\\n=== {prompt!r} ===\")\n",
    "    print(\"verify:\", out.get(\"verify\"))\n",
    "    print(\"plan:  \", out.get(\"plan\"))\n",
    "    print(\"flags: \", out.get(\"flags\"))\n",
    "    audit = ((out.get(\"artifacts\") or {}).get(\"audit\") or {})\n",
    "    trace = audit.get(\"trace\") or audit.get(\"profile\") or audit.get(\"log\")\n",
    "    if trace:\n",
    "        lines = trace if isinstance(trace, list) else str(trace).splitlines()\n",
    "        print(\"\\n[audit trace — first lines]\")\n",
    "        for ln in lines[:show_trace_lines]:\n",
    "            print(ln)\n",
    "    return out\n",
    "\n",
    "# 1) Supported exec: should now produce a plan and verify.ok=True\n",
    "out1 = call(\"deposit 10 ETH into aave\")\n",
    "assert (out1.get(\"plan\") or {}).get(\"sequence\"), \"expected an executable plan\"\n",
    "assert (out1.get(\"verify\") or {}).get(\"ok\") is True, \"expected verify.ok=True for a safe deposit\"\n",
    "\n",
    "# 2) Your earlier SOL/Maker example will still abstain unless you register them:\n",
    "out2 = call(\"supply 7.0245 SOL to maker\")\n",
    "\n",
    "# If you want that to pass too, register SOL + maker and try again:\n",
    "CONTEXT[\"defi\"][\"assets\"][\"SOL\"] = {\"symbol\":\"SOL\",\"decimals\":9, \"chain\":\"solana\"}  # adjust to your rails’ schema\n",
    "CONTEXT[\"defi\"][\"venues\"][\"maker\"] = {\"type\":\"lending\", \"version\":\"v3\", \"chain\":\"ethereum\"}  # or whatever your rails expect\n",
    "out3 = call(\"supply 7.0245 SOL to maker\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb9ed05a-c659-4c44-a0e1-ebed7d624a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verify: None\n",
      "plan: None\n",
      "top1: deposit_asset flags: {'mapper_fallback': True}\n"
     ]
    }
   ],
   "source": [
    "import os, sys, warnings, joblib, numpy as np\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Ensure src/ is importable\n",
    "SRC = os.path.join(os.getcwd(), \"src\")\n",
    "if SRC not in sys.path: sys.path.insert(0, SRC)\n",
    "\n",
    "# Import Tier-2 runner\n",
    "from micro_lm.core.runner import run_micro\n",
    "\n",
    "# Tier-2 style policy = Stage-11 rails + WDD audit + mapper fallback\n",
    "POLICY = {\n",
    "    \"ltv_max\": 0.75,\n",
    "    \"hf_min\": 1.0,\n",
    "    \"audit\": {\"backend\": \"wdd\", \"mode\": \"pure\", \"profile\": False, \"max_null\": 64, \"batch\": 32},\n",
    "    \"mapper\": {\"model_path\": \".artifacts/defi_mapper.joblib\", \"confidence_threshold\": 0.45},\n",
    "}\n",
    "CONTEXT = {\"oracle\": {\"age_sec\": 5, \"max_age_sec\": 30}}\n",
    "\n",
    "# Example Tier-2 prompt\n",
    "prompt = \"supply 7.0245 SOL to maker\"\n",
    "\n",
    "# Call the real Stage-11 rails pipeline\n",
    "out = run_micro(\n",
    "    domain=\"defi\",\n",
    "    prompt=prompt,\n",
    "    context=CONTEXT,\n",
    "    policy=POLICY,\n",
    "    rails=\"stage11\",\n",
    "    T=180,\n",
    ")\n",
    "\n",
    "# If no plan was produced, do mapper fallback (like tier2_benchmark)\n",
    "def _predict_one(model, text):\n",
    "    if hasattr(model, \"predict\"): return model.predict([text])[0]\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        proba = model.predict_proba([text])[0]\n",
    "        labels = getattr(model, \"classes_\", None)\n",
    "        return labels[int(np.argmax(proba))] if labels is not None else None\n",
    "\n",
    "seq = (out.get(\"plan\") or {}).get(\"sequence\") or []\n",
    "top1 = seq[0] if seq else None\n",
    "if top1 is None and POLICY.get(\"mapper\", {}).get(\"model_path\"):\n",
    "    mapper = joblib.load(POLICY[\"mapper\"][\"model_path\"])\n",
    "    m_top1 = _predict_one(mapper, prompt)\n",
    "    if m_top1:\n",
    "        top1 = m_top1\n",
    "        out.setdefault(\"flags\", {})[\"mapper_fallback\"] = True\n",
    "\n",
    "print(\"verify:\", out.get(\"verify\"))\n",
    "print(\"plan:\", out.get(\"plan\"))\n",
    "print(\"top1:\", top1, \"flags:\", out.get(\"flags\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
