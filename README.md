# micro-llm

NGF-powered micro-LLMs: lightweight, domain-specific reasoning sidecars.  
This repo is a research testbed: first for **ARC** (visual reasoning), then for a **DeFi** PoC â€” both built on top of the `ngeodesic` Python package.

---

## Why this repo?

- **ARC micro-LLM (today):** a compact, NGF-style classifier that detects and orders latent â€œprimitivesâ€ on synthetic ARC-like traces. It demonstrates the **Adapter â†’ Detect** path and stable metrics.
- **DeFi micro-LLM (next):** same skeleton, different adapter â€” turn market features into latent traces and reuse the exact parser/denoiser stack.

> NGFâ€™s repeatable pipeline: **Adapter â†’ Warp â†’ Detect â†’ Denoise â†’ Execute â†’ Verify**. Here we focus on Adapterâ†’Detect (+optional Denoise) for a small, reliable sidecar you can pair with a larger LLM.

---

## Foundation: `ngeodesic` (NGF Stage-10/11)

- **Stage-10 (Parser):** matched-filter parsing with dual thresholds (absolute vs null; relative vs best channel), then ordering by peak time.
- **Stage-11 (Denoise):** stabilization via hybrid EMA+median smoothing, confidence gates, seed-jitter averaging â€” the Warpâ†’Detectâ†’Denoise doctrine to suppress phantoms.

These are provided by the `ngeodesic` package and reused here without modification.

---

## Whatâ€™s included

- **ARC sandbox**: synthetic adapters that produce per-primitive traces; evaluation scripts that compute accuracy, precision/recall/F1, and NGF-native rates (hallucination/omission).
- **DeFi stubs (WIP)**: adapters for market features â†’ latent traces; same parser/denoiser stack; same metrics.

### ARC micro PoC â€” run a reasoning primitive
micro-arc --prompt "flip the grid horizontally" --rails stage11

#### Example output:
{
  "domain": "arc",
  "rails": "stage11",
  "plan": {
    "sequence": ["flip_h"]
  },
  "verify": {"ok": true, "reason": ""}
}

---

## DeFi Micro-LLM: Tiered Plan of Attack

This repo hosts experiments in **micro-scale language models** with **domain-specific reasoning**. Our current focus is the DeFi domain, but the architecture generalizes to other verticals. Each tier represents an increasing level of capability and integration. 

---

### **Tier-0: Baseline Deterministic Rails (âœ” Secured)**  
- **Stock matched filter + parser** pipeline.  
- Supports core DeFi primitives with deterministic abstain paths.  
- Sandbox verified and benchmarked with stable execution.

**Status:** âœ… Complete â€” foundation secured.

### **Tier-1: Micro-LLM on Synthetic Latents (In Progress)**  
- Replace hashmap lookups with a **trained micro-LLM encoder**.  
- Train against **2â€“5k synthetic latent prompts**.  
- Benchmark with full Stage-11 runner on DeFi suites.

**Status:** ðŸ‘· In progress â€” LLM benchmarks confirm deterministic reasoning on synthetic latents (MVP)

### **Tier-2: Incorporate WDD with Synthetic Latents (Operational)**  
- Add **Warp â†’ Detect â†’ Denoise (WDD)** pipeline.  
- Stress test signal separation + denoising with synthetic latents.

**Status:** ðŸš§ Proven â€” WDD LLM benchmarks confirm deterministic reasoning on synthetic latents.

### **Tier-3: Real Latents (End Goal)**  
- Swap synthetic latents for **true model latents**.  
- Validate WDD under real-world latent distributions.

**Status:** ðŸ”® Planning stage â€” future work, not required for MVP.

---

**Roadmap Summary:**  
- Tiers 0 + 1 provide a safe, working MVP with deterministic rails and micro-LLM reasoning on synthetic latents.
- Tier 2 expands the scope of what micro-LLM can do
- Tier 3 remains a the end goal: sidecar integration for real latents, to be explored later.


## Install

```bash
# 1) Install the NGF core
python3 -m pip install -U ngeodesic

# 2) (optional) install this repo in editable mode
git clone https://github.com/ngeodesic-ai/micro-llm.git
cd micro-llm
python3 -m pip install -e .
```